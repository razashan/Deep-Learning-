{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEP REINFORCEMENT LEARNING FOR GAMES.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDWlLFq2rb1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8a066779-0280-46d7-fd8c-ba8c36053b87"
      },
      "source": [
        "import os\n",
        "import pickle \n",
        "import random\n",
        "import zlib\n",
        "from collections import deque\n",
        "from collections import namedtuple\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlzGUST8tA3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resume = True\n",
        "CHECKPOINT_PATH = 'deep_q_breakout_path_8'\n",
        "MB_SIZE = 32\n",
        "ER_BUFFER_SIZE = 1000000\n",
        "COMPRESS_ER = True\n",
        "EXPLORE_STEPS = 1000000\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_END = 0.01\n",
        "STATE_FRAMES = 4\n",
        "SAVE_EVERY_X_STEPS = 10000\n",
        "UPDATE_Q_NET_FREQ = 1\n",
        "UPDATE_TARGET_NET_EVERY_X_STEPS = 10000\n",
        "DISCOUNT_FACTOR = 0.99"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pl1698Ptylb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize():\n",
        "    \"\"\"Initialize the session, the networks, and the environment\"\"\"\n",
        "    # Create environment\n",
        "    env = gym.envs.make(\"BreakoutDeterministic-v4\")\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    session = tf.Session()\n",
        "\n",
        "    # Tracks the total nubmer of training steps\n",
        "    tf.Variable(0, name='global_step', trainable=False)\n",
        "\n",
        "    # Create q- and target- networks\n",
        "    q_network = build_network(\"q_network\")\n",
        "    t_network = build_network(\"target_network\")\n",
        "\n",
        "    # create the operations to copy the q-net weights to the t-net\n",
        "    q_net_weights = [t for t in tf.trainable_variables() if t.name.startswith(q_network.scope)]\n",
        "    q_net_weights = sorted(q_net_weights, key=lambda v: v.name)\n",
        "    t_net_weights = [t for t in tf.trainable_variables() if t.name.startswith(t_network.scope)]\n",
        "    t_net_weights = sorted(t_net_weights, key=lambda v: v.name)\n",
        "\n",
        "    t_net_updates = \\\n",
        "        [n2_v.assign(n1_v) for n1_v, n2_v in zip(q_net_weights, t_net_weights)]\n",
        "\n",
        "    # pre-processor of game frames\n",
        "    frame_proc = frame_preprocessor()\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(0.00025)\n",
        "    # optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)\n",
        "\n",
        "    # training op\n",
        "    train_op = optimizer.minimize(q_network.loss, global_step=tf.train.get_global_step())\n",
        "\n",
        "    # restore checkpoint\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    if not os.path.exists(CHECKPOINT_PATH):\n",
        "        os.mkdir(CHECKPOINT_PATH)\n",
        "\n",
        "    checkpoint = tf.train.get_checkpoint_state(CHECKPOINT_PATH)\n",
        "    if resume and checkpoint:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        session.run(tf.local_variables_initializer())\n",
        "\n",
        "        print(\"\\nRestoring checkpoint...\")\n",
        "        saver.restore(session, checkpoint.model_checkpoint_path)\n",
        "    else:\n",
        "        session.run(tf.global_variables_initializer())\n",
        "        session.run(tf.local_variables_initializer())\n",
        "\n",
        "    return session, \\\n",
        "           q_network, \\\n",
        "           t_network, \\\n",
        "           t_net_updates, \\\n",
        "           frame_proc, \\\n",
        "           saver, \\\n",
        "           train_op, \\\n",
        "           env\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnP49hONxD0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_network(scope: str, input_size=84, num_actions=4):\n",
        "    \"\"\"Builds the network graph.\"\"\"\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "        # Our input are STATE_FRAMES greyscale frames of shape 84, 84 each\n",
        "        input_placeholder = tf.placeholder(dtype=np.float32,\n",
        "                                           shape=[None, input_size, input_size, STATE_FRAMES])\n",
        "\n",
        "        normalized_input = tf.to_float(input_placeholder) / 255.0\n",
        "\n",
        "        # action prediction\n",
        "        action_placeholder = tf.placeholder(dtype=tf.int32, shape=[None])\n",
        "\n",
        "        # target action\n",
        "        target_placeholder = tf.placeholder(dtype=np.float32, shape=[None])\n",
        "\n",
        "        # Convolutional layers\n",
        "        conv_1 = tf.layers.conv2d(normalized_input, 32, 8, 4,\n",
        "                                  activation=tf.nn.relu)\n",
        "        conv_2 = tf.layers.conv2d(conv_1, 64, 4, 2,\n",
        "                                  activation=tf.nn.relu)\n",
        "        conv_3 = tf.layers.conv2d(conv_2, 64, 3, 1,\n",
        "                                  activation=tf.nn.relu)\n",
        "\n",
        "        # Fully connected layers\n",
        "        flattened = tf.layers.flatten(conv_3)\n",
        "        fc_1 = tf.layers.dense(flattened, 512,\n",
        "                               activation=tf.nn.relu)\n",
        "\n",
        "        q_estimation = tf.layers.dense(fc_1, num_actions)\n",
        "\n",
        "        # Get the predictions for the chosen actions only\n",
        "        batch_size = tf.shape(normalized_input)[0]\n",
        "        gather_indices = tf.range(batch_size) * tf.shape(q_estimation)[1] + action_placeholder\n",
        "        action_predictions = tf.gather(tf.reshape(q_estimation, [-1]), gather_indices)\n",
        "\n",
        "        # Calculate the loss\n",
        "        # loss = tf.reduce_mean(tf.squared_difference(target_placeholder, action_predictions))\n",
        "        loss = tf.losses.huber_loss(labels=target_placeholder, predictions=action_predictions, reduction=tf.losses.Reduction.MEAN)\n",
        "\n",
        "    Network = namedtuple('Network',\n",
        "                         'scope '\n",
        "                         'input_placeholder '\n",
        "                         'action_placeholder '\n",
        "                         'target_placeholder '\n",
        "                         'q_estimation '\n",
        "                         'action_predictions '\n",
        "                         'loss ')\n",
        "\n",
        "    return Network(scope=scope,\n",
        "                   input_placeholder=input_placeholder,\n",
        "                   action_placeholder=action_placeholder,\n",
        "                   target_placeholder=target_placeholder,\n",
        "                   q_estimation=q_estimation,\n",
        "                   action_predictions=action_predictions,\n",
        "                   loss=loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KDouDr918ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_next_action(state, net, epsilon):\n",
        "    \"\"\"Epsilon-greedy policy\"\"\"\n",
        "\n",
        "    # choose an action given our last state\n",
        "    tmp = np.ones(env.action_space.n, dtype=float) * epsilon / env.action_space.n\n",
        "    q_estimations = session.run(net.q_estimation,\n",
        "        feed_dict={net.input_placeholder: np.reshape(state, (1,) + state.shape)})[0]\n",
        "\n",
        "    tmp[np.argmax(q_estimations)] += (1.0 - epsilon)\n",
        "\n",
        "    new_action = np.random.choice(np.arange(len(tmp)), p=tmp)\n",
        "\n",
        "    return new_action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCunv5zs3TpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def frame_preprocessor():\n",
        "    \"\"\"Pre-processing the input data\"\"\"\n",
        "\n",
        "    with tf.variable_scope(\"frame_processor\"):\n",
        "        input_placeholder = tf.placeholder(shape=[210, 160, 3], dtype=tf.uint8)\n",
        "        processed_frame = tf.image.rgb_to_grayscale(input_placeholder)\n",
        "        processed_frame = tf.image.crop_to_bounding_box(processed_frame, 34, 0, 160, 160)\n",
        "        processed_frame = tf.image.resize_images(\n",
        "            processed_frame,\n",
        "            [84, 84],\n",
        "            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "        processed_frame = tf.squeeze(processed_frame)\n",
        "\n",
        "    FramePreprocessor = namedtuple('FramePreprocessor', 'input_placeholder processed_frame')\n",
        "\n",
        "    return FramePreprocessor(\n",
        "        input_placeholder=input_placeholder,\n",
        "        processed_frame=processed_frame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPPQLQo76rPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def populate_experience_replay_buffer(buffer: deque, initial_buffer_size: int):\n",
        "    \"\"\"Initial population of the experience replay buffer\"\"\"\n",
        "\n",
        "    # Initialize epsilon based on the current step\n",
        "    epsilon_step = (EPSILON_START - EPSILON_END) / EXPLORE_STEPS\n",
        "    epsilon = max(EPSILON_END,\n",
        "                  EPSILON_START -\n",
        "                  session.run(tf.train.get_global_step()) * epsilon_step)\n",
        "\n",
        "    # Populate the replay memory with initial experience\n",
        "    state = env.reset()\n",
        "    state = session.run(frame_proc.processed_frame,\n",
        "                        feed_dict={frame_proc.input_placeholder: state})\n",
        "\n",
        "    state = np.stack([state] * STATE_FRAMES, axis=2)\n",
        "\n",
        "    for i in range(initial_buffer_size):\n",
        "\n",
        "        # Sample next state with the q_network\n",
        "        action = choose_next_action(state, q_network, epsilon)\n",
        "\n",
        "        # Perform one action step\n",
        "        next_state, reward, terminal, info = env.step(action)\n",
        "        next_state = session.run(frame_proc.processed_frame,\n",
        "                                 feed_dict={frame_proc.input_placeholder: next_state})\n",
        "\n",
        "        # Stack the game frames in a single array\n",
        "        next_state = np.append(state[:, :, 1:], np.expand_dims(next_state, 2), axis=2)\n",
        "\n",
        "        # Store the experience in ER\n",
        "        if COMPRESS_ER:\n",
        "            buffer.append(\n",
        "                zlib.compress(\n",
        "                    pickle.dumps((state, action, reward, next_state, terminal), 2), 2))\n",
        "        else:\n",
        "            buffer.append((state, action, reward, next_state, terminal))\n",
        "\n",
        "        # Set next state as current\n",
        "        if terminal:\n",
        "            state = env.reset()\n",
        "            state = session.run(frame_proc.processed_frame,\n",
        "                                feed_dict={frame_proc.input_placeholder: state})\n",
        "\n",
        "            state = np.stack([state] * STATE_FRAMES, axis=2)\n",
        "        else:\n",
        "            state = next_state\n",
        "\n",
        "        print(\"\\rExperience replay buffer: {} / {} initial ({} total)\".format(\n",
        "            len(buffer), initial_buffer_size, buffer.maxlen), end=\"\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11kgsn88gHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_stats(stats):\n",
        "    \"\"\"Plot the stats\"\"\"\n",
        "    plt.figure()\n",
        "\n",
        "    plt.xlabel(\"Episode\")\n",
        "\n",
        "    # plot the rewards\n",
        "    # rolling mean of 50\n",
        "    cumsum = np.cumsum(np.insert(stats.rewards, 0, 0))\n",
        "    rewards = (cumsum[50:] - cumsum[:-50]) / float(50)\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    color = 'tab:red'\n",
        "\n",
        "    ax1.set_ylabel('Reward', color=color)\n",
        "    ax1.plot(rewards, color=color)\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # plot the episode lengths\n",
        "    # rolling mean of 50\n",
        "    cumsum = np.cumsum(np.insert(stats.lengths, 0, 0))\n",
        "    lengths = (cumsum[50:] - cumsum[:-50]) / float(50)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('Length', color=color)\n",
        "    ax2.plot(lengths, color=color)\n",
        "    ax2.tick_params(axis='y', labelcolor=color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOKv07PLBzPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4216824-3674-4bf8-9039-9e153f618367"
      },
      "source": [
        "def deep_q_learning():\n",
        "    \"\"\"The Q-learning training process\"\"\"\n",
        "\n",
        "    # build experience replay\n",
        "    observations = deque(maxlen=ER_BUFFER_SIZE)\n",
        "\n",
        "    print(\"Populating replay memory...\")\n",
        "    populate_experience_replay_buffer(observations, 100000)\n",
        "\n",
        "    # initialize statistics\n",
        "    stats = namedtuple('Stats', 'rewards lengths')(rewards=list(), lengths=list())\n",
        "    global_time = session.run(tf.train.get_global_step())\n",
        "    time = 0\n",
        "\n",
        "    episode = 1\n",
        "\n",
        "    episode_reward = 0\n",
        "    global_reward = 0\n",
        "\n",
        "    # Start the training with an initial state\n",
        "    state = env.reset()\n",
        "    state = session.run(frame_proc.processed_frame,\n",
        "                        feed_dict={frame_proc.input_placeholder: state})\n",
        "    state = np.stack([state] * STATE_FRAMES, axis=2)\n",
        "\n",
        "    while True:\n",
        "        # env.render()\n",
        "\n",
        "        # Initialize epsilon based on the current step\n",
        "        epsilon_step = (EPSILON_START - EPSILON_END) / EXPLORE_STEPS\n",
        "        epsilon = max(EPSILON_END, EPSILON_START - (global_time - 1) * epsilon_step)\n",
        "\n",
        "        # Copy q-net weights to the target-net\n",
        "        if global_time % UPDATE_TARGET_NET_EVERY_X_STEPS == 0:\n",
        "            session.run(t_net_updates)\n",
        "            print(\"\\nCopied model parameters to target network.\")\n",
        "\n",
        "        # Sample next action\n",
        "        action = choose_next_action(state, q_network, epsilon)\n",
        "\n",
        "        # Perform one step with the selected action\n",
        "        next_state, reward, terminal, info = env.step(action)\n",
        "\n",
        "        # This is how we pre-process\n",
        "        next_state = session.run(frame_proc.processed_frame,\n",
        "                                 feed_dict={frame_proc.input_placeholder: next_state})\n",
        "\n",
        "        # Stack the game frames in a single array\n",
        "        next_state = np.append(state[:, :, 1:], np.expand_dims(next_state, 2), axis=2)\n",
        "\n",
        "        # Store the experience in ER\n",
        "        if COMPRESS_ER:\n",
        "            observations.append(\n",
        "                zlib.compress(pickle.dumps((state, action, reward, next_state, terminal), 2), 2))\n",
        "        else:\n",
        "            observations.append((state, action, reward, next_state, terminal))\n",
        "\n",
        "        # Sample a mini-batch from the experience replay memory\n",
        "        mini_batch = random.sample(observations, MB_SIZE)\n",
        "        if COMPRESS_ER:\n",
        "            mini_batch = [pickle.loads(zlib.decompress(comp_item)) for comp_item in mini_batch]\n",
        "\n",
        "        states_batch, action_batch, reward_batch, next_states_batch, terminal_batch = \\\n",
        "            map(np.array, zip(*mini_batch))\n",
        "\n",
        "        # Double Q-learning\n",
        "        if global_time % UPDATE_Q_NET_FREQ == 0:\n",
        "            # First predict the next q values with the q-network\n",
        "            q_values_next = session.run(q_network.q_estimation,\n",
        "                                        feed_dict={q_network.input_placeholder: next_states_batch})\n",
        "\n",
        "            # The best action according to the q-network\n",
        "            best_actions = np.argmax(q_values_next, axis=1)\n",
        "\n",
        "            # Next, predict the next q values with the target-network\n",
        "            q_values_next_target = session.run(t_network.q_estimation,\n",
        "                                               feed_dict={t_network.input_placeholder: next_states_batch})\n",
        "\n",
        "            # Calculate q values and targets\n",
        "            # Use the t-network estimations\n",
        "            # But with the best action, selected by the q-network (Double Q-learning)\n",
        "            targets_batch = reward_batch + \\\n",
        "                            np.invert(terminal_batch).astype(np.float32) * \\\n",
        "                            DISCOUNT_FACTOR * \\\n",
        "                            q_values_next_target[np.arange(MB_SIZE), best_actions]\n",
        "\n",
        "            _, loss = session.run([train_op, q_network.loss],\n",
        "                                  feed_dict={\n",
        "                                      q_network.input_placeholder: states_batch,\n",
        "                                      q_network.action_placeholder: action_batch,\n",
        "                                      q_network.target_placeholder: targets_batch})\n",
        "\n",
        "        episode_reward += reward\n",
        "        global_reward += reward\n",
        "        time += 1\n",
        "        global_time += 1\n",
        "\n",
        "        print(\"\\rEpisode {}: \"\n",
        "              \"time {:5}; \"\n",
        "              \"reward {}; \"\n",
        "              \"epsilon: {:.4f}; \"\n",
        "              \"loss: {:.6f}; \"\n",
        "              \"@ global step {} \"\n",
        "              \"with total reward {}\".format(\n",
        "            episode,\n",
        "            time,\n",
        "            episode_reward,\n",
        "            epsilon,\n",
        "            loss,\n",
        "            global_time,\n",
        "            global_reward), end=\"\")\n",
        "\n",
        "        if terminal:\n",
        "            # Episode end\n",
        "\n",
        "            print()\n",
        "\n",
        "            stats.rewards.append(int(episode_reward))\n",
        "            stats.lengths.append(time)\n",
        "\n",
        "            time = 0\n",
        "            episode_reward = 0\n",
        "            episode += 1\n",
        "\n",
        "            state = env.reset()\n",
        "            state = session.run(frame_proc.processed_frame,\n",
        "                                feed_dict={frame_proc.input_placeholder: state})\n",
        "            state = np.stack([state] * STATE_FRAMES, axis=2)\n",
        "        else:\n",
        "            # Set next state as current\n",
        "            state = next_state\n",
        "\n",
        "        # save checkpoints for later\n",
        "        if global_time % SAVE_EVERY_X_STEPS == 0:\n",
        "            saver.save(session, CHECKPOINT_PATH + '/network',\n",
        "                       global_step=tf.train.get_global_step())\n",
        "\n",
        "            # plot the results and save the figure\n",
        "            plot_stats(stats)\n",
        "\n",
        "            fig_file = CHECKPOINT_PATH + '/stats.png'\n",
        "            if os.path.isfile(fig_file):\n",
        "                os.remove(fig_file)\n",
        "\n",
        "            plt.savefig(fig_file)\n",
        "            plt.close()\n",
        "\n",
        "            # save the stats\n",
        "            with open(CHECKPOINT_PATH + '/stats.arr', 'wb') as f:\n",
        "                pickle.dump((stats.rewards, stats.lengths), f)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    session, q_network, t_network, t_net_updates, frame_proc, saver, train_op, env = \\\n",
        "        initialize()\n",
        "    deep_q_learning()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-0e13b7782775>:26: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-35-0e13b7782775>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "Populating replay memory...\n",
            "Experience replay buffer: 100000 / 100000 initial (1000000 total)\n",
            "Copied model parameters to target network.\n",
            "Episode 1: time   173; reward 1.0; epsilon: 0.9998; loss: 0.015255; @ global step 173 with total reward 1.0\n",
            "Episode 2: time   148; reward 0.0; epsilon: 0.9997; loss: 0.000024; @ global step 321 with total reward 1.0\n",
            "Episode 3: time   132; reward 0.0; epsilon: 0.9996; loss: 0.001596; @ global step 453 with total reward 1.0\n",
            "Episode 4: time   136; reward 0.0; epsilon: 0.9994; loss: 0.000969; @ global step 589 with total reward 1.0\n",
            "Episode 5: time   137; reward 0.0; epsilon: 0.9993; loss: 0.000262; @ global step 726 with total reward 1.0\n",
            "Episode 6: time   169; reward 1.0; epsilon: 0.9991; loss: 0.000055; @ global step 895 with total reward 2.0\n",
            "Episode 7: time   231; reward 2.0; epsilon: 0.9989; loss: 0.016223; @ global step 1126 with total reward 4.0\n",
            "Episode 8: time   211; reward 2.0; epsilon: 0.9987; loss: 0.000007; @ global step 1337 with total reward 6.0\n",
            "Episode 9: time   251; reward 3.0; epsilon: 0.9984; loss: 0.015280; @ global step 1588 with total reward 9.0\n",
            "Episode 10: time   136; reward 0.0; epsilon: 0.9983; loss: 0.000047; @ global step 1724 with total reward 9.0\n",
            "Episode 11: time   207; reward 2.0; epsilon: 0.9981; loss: 0.000802; @ global step 1931 with total reward 11.0\n",
            "Episode 12: time   273; reward 3.0; epsilon: 0.9978; loss: 0.000044; @ global step 2204 with total reward 14.0\n",
            "Episode 13: time   138; reward 0.0; epsilon: 0.9977; loss: 0.000137; @ global step 2342 with total reward 14.0\n",
            "Episode 14: time   183; reward 1.0; epsilon: 0.9975; loss: 0.000149; @ global step 2525 with total reward 15.0\n",
            "Episode 15: time   148; reward 0.0; epsilon: 0.9974; loss: 0.001045; @ global step 2673 with total reward 15.0\n",
            "Episode 16: time   173; reward 1.0; epsilon: 0.9972; loss: 0.000089; @ global step 2846 with total reward 16.0\n",
            "Episode 17: time   137; reward 0.0; epsilon: 0.9970; loss: 0.000460; @ global step 2983 with total reward 16.0\n",
            "Episode 18: time   128; reward 0.0; epsilon: 0.9969; loss: 0.000143; @ global step 3111 with total reward 16.0\n",
            "Episode 19: time   230; reward 2.0; epsilon: 0.9967; loss: 0.000252; @ global step 3341 with total reward 18.0\n",
            "Episode 20: time   190; reward 2.0; epsilon: 0.9965; loss: 0.000771; @ global step 3531 with total reward 20.0\n",
            "Episode 21: time   133; reward 0.0; epsilon: 0.9964; loss: 0.000263; @ global step 3664 with total reward 20.0\n",
            "Episode 22: time   146; reward 0.0; epsilon: 0.9962; loss: 0.000487; @ global step 3810 with total reward 20.0\n",
            "Episode 23: time   211; reward 2.0; epsilon: 0.9960; loss: 0.000149; @ global step 4021 with total reward 22.0\n",
            "Episode 24: time   131; reward 0.0; epsilon: 0.9959; loss: 0.000854; @ global step 4152 with total reward 22.0\n",
            "Episode 25: time   219; reward 2.0; epsilon: 0.9957; loss: 0.000281; @ global step 4371 with total reward 24.0\n",
            "Episode 26: time   183; reward 1.0; epsilon: 0.9955; loss: 0.000813; @ global step 4554 with total reward 25.0\n",
            "Episode 27: time   131; reward 0.0; epsilon: 0.9954; loss: 0.000404; @ global step 4685 with total reward 25.0\n",
            "Episode 28: time   280; reward 4.0; epsilon: 0.9951; loss: 0.000247; @ global step 4965 with total reward 29.0\n",
            "Episode 29: time   255; reward 3.0; epsilon: 0.9948; loss: 0.000211; @ global step 5220 with total reward 32.0\n",
            "Episode 30: time   177; reward 1.0; epsilon: 0.9947; loss: 0.000022; @ global step 5397 with total reward 33.0\n",
            "Episode 31: time   127; reward 0.0; epsilon: 0.9945; loss: 0.001332; @ global step 5524 with total reward 33.0\n",
            "Episode 32: time   172; reward 1.0; epsilon: 0.9944; loss: 0.000124; @ global step 5696 with total reward 34.0\n",
            "Episode 33: time   157; reward 1.0; epsilon: 0.9942; loss: 0.000004; @ global step 5853 with total reward 35.0\n",
            "Episode 34: time   138; reward 0.0; epsilon: 0.9941; loss: 0.000173; @ global step 5991 with total reward 35.0\n",
            "Episode 35: time   137; reward 0.0; epsilon: 0.9939; loss: 0.000168; @ global step 6128 with total reward 35.0\n",
            "Episode 36: time   153; reward 1.0; epsilon: 0.9938; loss: 0.000147; @ global step 6281 with total reward 36.0\n",
            "Episode 37: time   155; reward 1.0; epsilon: 0.9936; loss: 0.000038; @ global step 6436 with total reward 37.0\n",
            "Episode 38: time   138; reward 0.0; epsilon: 0.9935; loss: 0.003147; @ global step 6574 with total reward 37.0\n",
            "Episode 39: time   208; reward 2.0; epsilon: 0.9933; loss: 0.000136; @ global step 6782 with total reward 39.0\n",
            "Episode 40: time   140; reward 0.0; epsilon: 0.9931; loss: 0.000309; @ global step 6922 with total reward 39.0\n",
            "Episode 41: time   201; reward 2.0; epsilon: 0.9930; loss: 0.000309; @ global step 7123 with total reward 41.0\n",
            "Episode 42: time   127; reward 0.0; epsilon: 0.9928; loss: 0.000443; @ global step 7250 with total reward 41.0\n",
            "Episode 43: time   154; reward 1.0; epsilon: 0.9927; loss: 0.000077; @ global step 7404 with total reward 42.0\n",
            "Episode 44: time   210; reward 2.0; epsilon: 0.9925; loss: 0.000068; @ global step 7614 with total reward 44.0\n",
            "Episode 45: time   160; reward 1.0; epsilon: 0.9923; loss: 0.001269; @ global step 7774 with total reward 45.0\n",
            "Episode 46: time   130; reward 0.0; epsilon: 0.9922; loss: 0.000166; @ global step 7904 with total reward 45.0\n",
            "Episode 47: time   137; reward 0.0; epsilon: 0.9920; loss: 0.001295; @ global step 8041 with total reward 45.0\n",
            "Episode 48: time   227; reward 3.0; epsilon: 0.9918; loss: 0.001435; @ global step 8268 with total reward 48.0\n",
            "Episode 49: time   181; reward 1.0; epsilon: 0.9916; loss: 0.000982; @ global step 8449 with total reward 49.0\n",
            "Episode 50: time   189; reward 2.0; epsilon: 0.9915; loss: 0.000255; @ global step 8638 with total reward 51.0\n",
            "Episode 51: time   180; reward 1.0; epsilon: 0.9913; loss: 0.000105; @ global step 8818 with total reward 52.0\n",
            "Episode 52: time   134; reward 0.0; epsilon: 0.9911; loss: 0.000085; @ global step 8952 with total reward 52.0\n",
            "Episode 53: time   133; reward 0.0; epsilon: 0.9910; loss: 0.000199; @ global step 9085 with total reward 52.0\n",
            "Episode 54: time   132; reward 0.0; epsilon: 0.9909; loss: 0.000244; @ global step 9217 with total reward 52.0\n",
            "Episode 55: time   194; reward 2.0; epsilon: 0.9907; loss: 0.001436; @ global step 9411 with total reward 54.0\n",
            "Episode 56: time   172; reward 1.0; epsilon: 0.9905; loss: 0.000352; @ global step 9583 with total reward 55.0\n",
            "Episode 57: time   160; reward 1.0; epsilon: 0.9904; loss: 0.000011; @ global step 9743 with total reward 56.0\n",
            "Episode 58: time   159; reward 1.0; epsilon: 0.9902; loss: 0.000038; @ global step 9902 with total reward 57.0\n",
            "Episode 59: time    98; reward 0.0; epsilon: 0.9901; loss: 0.000126; @ global step 10000 with total reward 57.0\n",
            "Copied model parameters to target network.\n",
            "Episode 59: time   165; reward 1.0; epsilon: 0.9900; loss: 0.000032; @ global step 10067 with total reward 58.0\n",
            "Episode 60: time   181; reward 1.0; epsilon: 0.9899; loss: 0.000025; @ global step 10248 with total reward 59.0\n",
            "Episode 61: time   167; reward 1.0; epsilon: 0.9897; loss: 0.000014; @ global step 10415 with total reward 60.0\n",
            "Episode 62: time   136; reward 0.0; epsilon: 0.9896; loss: 0.001402; @ global step 10551 with total reward 60.0\n",
            "Episode 63: time   195; reward 2.0; epsilon: 0.9894; loss: 0.000019; @ global step 10746 with total reward 62.0\n",
            "Episode 64: time   189; reward 1.0; epsilon: 0.9892; loss: 0.000260; @ global step 10935 with total reward 63.0\n",
            "Episode 65: time   178; reward 1.0; epsilon: 0.9890; loss: 0.000007; @ global step 11113 with total reward 64.0\n",
            "Episode 66: time   175; reward 1.0; epsilon: 0.9888; loss: 0.000012; @ global step 11288 with total reward 65.0\n",
            "Episode 67: time   248; reward 3.0; epsilon: 0.9886; loss: 0.000003; @ global step 11536 with total reward 68.0\n",
            "Episode 68: time   149; reward 0.0; epsilon: 0.9884; loss: 0.000015; @ global step 11685 with total reward 68.0\n",
            "Episode 69: time   135; reward 0.0; epsilon: 0.9883; loss: 0.000009; @ global step 11820 with total reward 68.0\n",
            "Episode 70: time   138; reward 0.0; epsilon: 0.9882; loss: 0.000010; @ global step 11958 with total reward 68.0\n",
            "Episode 71: time   196; reward 1.0; epsilon: 0.9880; loss: 0.002710; @ global step 12154 with total reward 69.0\n",
            "Episode 72: time   143; reward 0.0; epsilon: 0.9878; loss: 0.000317; @ global step 12297 with total reward 69.0\n",
            "Episode 73: time   219; reward 2.0; epsilon: 0.9876; loss: 0.000006; @ global step 12516 with total reward 71.0\n",
            "Episode 74: time   141; reward 0.0; epsilon: 0.9875; loss: 0.000400; @ global step 12657 with total reward 71.0\n",
            "Episode 75: time   201; reward 2.0; epsilon: 0.9873; loss: 0.000020; @ global step 12858 with total reward 73.0\n",
            "Episode 76: time   127; reward 0.0; epsilon: 0.9871; loss: 0.000007; @ global step 12985 with total reward 73.0\n",
            "Episode 77: time   178; reward 1.0; epsilon: 0.9870; loss: 0.000003; @ global step 13163 with total reward 74.0\n",
            "Episode 78: time   159; reward 1.0; epsilon: 0.9868; loss: 0.000229; @ global step 13322 with total reward 75.0\n",
            "Episode 79: time   221; reward 3.0; epsilon: 0.9866; loss: 0.001593; @ global step 13543 with total reward 78.0\n",
            "Episode 80: time   161; reward 1.0; epsilon: 0.9864; loss: 0.000011; @ global step 13704 with total reward 79.0\n",
            "Episode 81: time   203; reward 2.0; epsilon: 0.9862; loss: 0.000016; @ global step 13907 with total reward 81.0\n",
            "Episode 82: time   160; reward 1.0; epsilon: 0.9861; loss: 0.000008; @ global step 14067 with total reward 82.0\n",
            "Episode 83: time   129; reward 0.0; epsilon: 0.9859; loss: 0.000334; @ global step 14196 with total reward 82.0\n",
            "Episode 84: time   225; reward 2.0; epsilon: 0.9857; loss: 0.000003; @ global step 14421 with total reward 84.0\n",
            "Episode 85: time   186; reward 2.0; epsilon: 0.9855; loss: 0.000004; @ global step 14607 with total reward 86.0\n",
            "Episode 86: time   155; reward 1.0; epsilon: 0.9854; loss: 0.000028; @ global step 14762 with total reward 87.0\n",
            "Episode 87: time   143; reward 0.0; epsilon: 0.9852; loss: 0.000009; @ global step 14905 with total reward 87.0\n",
            "Episode 88: time   290; reward 4.0; epsilon: 0.9850; loss: 0.000004; @ global step 15195 with total reward 91.0\n",
            "Episode 89: time   132; reward 0.0; epsilon: 0.9848; loss: 0.008584; @ global step 15327 with total reward 91.0\n",
            "Episode 90: time   128; reward 0.0; epsilon: 0.9847; loss: 0.000010; @ global step 15455 with total reward 91.0\n",
            "Episode 91: time   204; reward 2.0; epsilon: 0.9845; loss: 0.000017; @ global step 15659 with total reward 93.0\n",
            "Episode 92: time   148; reward 0.0; epsilon: 0.9844; loss: 0.000006; @ global step 15807 with total reward 93.0\n",
            "Episode 93: time   125; reward 0.0; epsilon: 0.9842; loss: 0.000016; @ global step 15932 with total reward 93.0\n",
            "Episode 94: time   255; reward 3.0; epsilon: 0.9840; loss: 0.000007; @ global step 16187 with total reward 96.0\n",
            "Episode 95: time   132; reward 0.0; epsilon: 0.9838; loss: 0.000002; @ global step 16319 with total reward 96.0\n",
            "Episode 96: time   140; reward 0.0; epsilon: 0.9837; loss: 0.000006; @ global step 16459 with total reward 96.0\n",
            "Episode 97: time   208; reward 2.0; epsilon: 0.9835; loss: 0.000008; @ global step 16667 with total reward 98.0\n",
            "Episode 98: time   212; reward 2.0; epsilon: 0.9833; loss: 0.000048; @ global step 16879 with total reward 100.0\n",
            "Episode 99: time   139; reward 0.0; epsilon: 0.9832; loss: 0.000121; @ global step 17018 with total reward 100.0\n",
            "Episode 100: time   185; reward 1.0; epsilon: 0.9830; loss: 0.000020; @ global step 17203 with total reward 101.0\n",
            "Episode 101: time   144; reward 0.0; epsilon: 0.9828; loss: 0.000010; @ global step 17347 with total reward 101.0\n",
            "Episode 102: time   140; reward 0.0; epsilon: 0.9827; loss: 0.000003; @ global step 17487 with total reward 101.0\n",
            "Episode 103: time   232; reward 2.0; epsilon: 0.9825; loss: 0.000014; @ global step 17719 with total reward 103.0\n",
            "Episode 104: time   136; reward 0.0; epsilon: 0.9823; loss: 0.000025; @ global step 17855 with total reward 103.0\n",
            "Episode 105: time   204; reward 2.0; epsilon: 0.9821; loss: 0.000046; @ global step 18059 with total reward 105.0\n",
            "Episode 106: time   141; reward 0.0; epsilon: 0.9820; loss: 0.000005; @ global step 18200 with total reward 105.0\n",
            "Episode 107: time   137; reward 0.0; epsilon: 0.9818; loss: 0.003294; @ global step 18337 with total reward 105.0\n",
            "Episode 108: time   183; reward 1.0; epsilon: 0.9817; loss: 0.012347; @ global step 18520 with total reward 106.0\n",
            "Episode 109: time   135; reward 0.0; epsilon: 0.9815; loss: 0.000008; @ global step 18655 with total reward 106.0\n",
            "Episode 110: time   135; reward 0.0; epsilon: 0.9814; loss: 0.000487; @ global step 18790 with total reward 106.0\n",
            "Episode 111: time   133; reward 0.0; epsilon: 0.9813; loss: 0.000004; @ global step 18923 with total reward 106.0\n",
            "Episode 112: time   137; reward 0.0; epsilon: 0.9811; loss: 0.000006; @ global step 19060 with total reward 106.0\n",
            "Episode 113: time   128; reward 0.0; epsilon: 0.9810; loss: 0.000016; @ global step 19188 with total reward 106.0\n",
            "Episode 114: time   179; reward 1.0; epsilon: 0.9808; loss: 0.000381; @ global step 19367 with total reward 107.0\n",
            "Episode 115: time   139; reward 0.0; epsilon: 0.9807; loss: 0.004349; @ global step 19506 with total reward 107.0\n",
            "Episode 116: time   132; reward 0.0; epsilon: 0.9806; loss: 0.000002; @ global step 19638 with total reward 107.0\n",
            "Episode 117: time   163; reward 1.0; epsilon: 0.9804; loss: 0.000003; @ global step 19801 with total reward 108.0\n",
            "Episode 118: time   163; reward 1.0; epsilon: 0.9802; loss: 0.000007; @ global step 19964 with total reward 109.0\n",
            "Episode 119: time    36; reward 0.0; epsilon: 0.9802; loss: 0.000004; @ global step 20000 with total reward 109.0\n",
            "Copied model parameters to target network.\n",
            "Episode 119: time   183; reward 1.0; epsilon: 0.9801; loss: 0.000074; @ global step 20147 with total reward 110.0\n",
            "Episode 120: time   173; reward 1.0; epsilon: 0.9799; loss: 0.001581; @ global step 20320 with total reward 111.0\n",
            "Episode 121: time   144; reward 0.0; epsilon: 0.9797; loss: 0.000031; @ global step 20464 with total reward 111.0\n",
            "Episode 122: time   167; reward 1.0; epsilon: 0.9796; loss: 0.000097; @ global step 20631 with total reward 112.0\n",
            "Episode 123: time   130; reward 0.0; epsilon: 0.9794; loss: 0.000005; @ global step 20761 with total reward 112.0\n",
            "Episode 124: time   190; reward 1.0; epsilon: 0.9793; loss: 0.002142; @ global step 20951 with total reward 113.0\n",
            "Episode 125: time   130; reward 0.0; epsilon: 0.9791; loss: 0.000087; @ global step 21081 with total reward 113.0\n",
            "Episode 126: time   260; reward 3.0; epsilon: 0.9789; loss: 0.000007; @ global step 21341 with total reward 116.0\n",
            "Episode 127: time   177; reward 1.0; epsilon: 0.9787; loss: 0.000080; @ global step 21518 with total reward 117.0\n",
            "Episode 128: time   166; reward 1.0; epsilon: 0.9785; loss: 0.000003; @ global step 21684 with total reward 118.0\n",
            "Episode 129: time   176; reward 1.0; epsilon: 0.9784; loss: 0.000007; @ global step 21860 with total reward 119.0\n",
            "Episode 130: time   157; reward 0.0; epsilon: 0.9782; loss: 0.000220; @ global step 22017 with total reward 119.0\n",
            "Episode 131: time   209; reward 2.0; epsilon: 0.9780; loss: 0.000233; @ global step 22226 with total reward 121.0\n",
            "Episode 132: time   141; reward 0.0; epsilon: 0.9779; loss: 0.000001; @ global step 22367 with total reward 121.0\n",
            "Episode 133: time   206; reward 2.0; epsilon: 0.9777; loss: 0.000002; @ global step 22573 with total reward 123.0\n",
            "Episode 134: time   207; reward 2.0; epsilon: 0.9774; loss: 0.000003; @ global step 22780 with total reward 125.0\n",
            "Episode 135: time   141; reward 0.0; epsilon: 0.9773; loss: 0.000002; @ global step 22921 with total reward 125.0\n",
            "Episode 136: time   187; reward 2.0; epsilon: 0.9771; loss: 0.000109; @ global step 23108 with total reward 127.0\n",
            "Episode 137: time   133; reward 0.0; epsilon: 0.9770; loss: 0.000006; @ global step 23241 with total reward 127.0\n",
            "Episode 138: time   144; reward 0.0; epsilon: 0.9769; loss: 0.000004; @ global step 23385 with total reward 127.0\n",
            "Episode 139: time   213; reward 2.0; epsilon: 0.9766; loss: 0.000131; @ global step 23598 with total reward 129.0\n",
            "Episode 140: time   184; reward 1.0; epsilon: 0.9765; loss: 0.000015; @ global step 23782 with total reward 130.0\n",
            "Episode 141: time   265; reward 4.0; epsilon: 0.9762; loss: 0.000010; @ global step 24047 with total reward 134.0\n",
            "Episode 142: time   142; reward 0.0; epsilon: 0.9761; loss: 0.000005; @ global step 24189 with total reward 134.0\n",
            "Episode 143: time   124; reward 0.0; epsilon: 0.9759; loss: 0.000005; @ global step 24313 with total reward 134.0\n",
            "Episode 144: time   143; reward 0.0; epsilon: 0.9758; loss: 0.000024; @ global step 24456 with total reward 134.0\n",
            "Episode 145: time   261; reward 3.0; epsilon: 0.9755; loss: 0.000010; @ global step 24717 with total reward 137.0\n",
            "Episode 146: time   161; reward 1.0; epsilon: 0.9754; loss: 0.000006; @ global step 24878 with total reward 138.0\n",
            "Episode 147: time   209; reward 2.0; epsilon: 0.9752; loss: 0.003554; @ global step 25087 with total reward 140.0\n",
            "Episode 148: time   235; reward 2.0; epsilon: 0.9749; loss: 0.000008; @ global step 25322 with total reward 142.0\n",
            "Episode 149: time   355; reward 5.0; epsilon: 0.9746; loss: 0.000143; @ global step 25677 with total reward 147.0\n",
            "Episode 150: time   127; reward 0.0; epsilon: 0.9745; loss: 0.000002; @ global step 25804 with total reward 147.0\n",
            "Episode 151: time   160; reward 0.0; epsilon: 0.9743; loss: 0.000054; @ global step 25964 with total reward 147.0\n",
            "Episode 152: time   133; reward 0.0; epsilon: 0.9742; loss: 0.000002; @ global step 26097 with total reward 147.0\n",
            "Episode 153: time   182; reward 1.0; epsilon: 0.9740; loss: 0.001963; @ global step 26279 with total reward 148.0\n",
            "Episode 154: time   132; reward 0.0; epsilon: 0.9739; loss: 0.000003; @ global step 26411 with total reward 148.0\n",
            "Episode 155: time   155; reward 0.0; epsilon: 0.9737; loss: 0.000015; @ global step 26566 with total reward 148.0\n",
            "Episode 156: time   132; reward 0.0; epsilon: 0.9736; loss: 0.000844; @ global step 26698 with total reward 148.0\n",
            "Episode 157: time   128; reward 0.0; epsilon: 0.9734; loss: 0.000050; @ global step 26826 with total reward 148.0\n",
            "Episode 158: time   185; reward 1.0; epsilon: 0.9733; loss: 0.000003; @ global step 27011 with total reward 149.0\n",
            "Episode 159: time   206; reward 2.0; epsilon: 0.9731; loss: 0.000005; @ global step 27217 with total reward 151.0\n",
            "Episode 160: time   165; reward 1.0; epsilon: 0.9729; loss: 0.000010; @ global step 27382 with total reward 152.0\n",
            "Episode 161: time   181; reward 1.0; epsilon: 0.9727; loss: 0.000002; @ global step 27563 with total reward 153.0\n",
            "Episode 162: time   178; reward 1.0; epsilon: 0.9725; loss: 0.000002; @ global step 27741 with total reward 154.0\n",
            "Episode 163: time   204; reward 2.0; epsilon: 0.9723; loss: 0.000001; @ global step 27945 with total reward 156.0\n",
            "Episode 164: time   193; reward 1.0; epsilon: 0.9721; loss: 0.000002; @ global step 28138 with total reward 157.0\n",
            "Episode 165: time   208; reward 2.0; epsilon: 0.9719; loss: 0.000003; @ global step 28346 with total reward 159.0\n",
            "Episode 166: time   164; reward 1.0; epsilon: 0.9718; loss: 0.000003; @ global step 28510 with total reward 160.0\n",
            "Episode 167: time   139; reward 0.0; epsilon: 0.9716; loss: 0.000260; @ global step 28649 with total reward 160.0\n",
            "Episode 168: time   141; reward 0.0; epsilon: 0.9715; loss: 0.000002; @ global step 28790 with total reward 160.0\n",
            "Episode 169: time   175; reward 1.0; epsilon: 0.9713; loss: 0.000049; @ global step 28965 with total reward 161.0\n",
            "Episode 170: time   178; reward 1.0; epsilon: 0.9712; loss: 0.000001; @ global step 29143 with total reward 162.0\n",
            "Episode 171: time   167; reward 1.0; epsilon: 0.9710; loss: 0.000018; @ global step 29310 with total reward 163.0\n",
            "Episode 172: time   235; reward 2.0; epsilon: 0.9708; loss: 0.000007; @ global step 29545 with total reward 165.0\n",
            "Episode 173: time   226; reward 2.0; epsilon: 0.9705; loss: 0.000003; @ global step 29771 with total reward 167.0\n",
            "Episode 174: time   131; reward 0.0; epsilon: 0.9704; loss: 0.000040; @ global step 29902 with total reward 167.0\n",
            "Episode 175: time    98; reward 0.0; epsilon: 0.9703; loss: 0.000006; @ global step 30000 with total reward 167.0\n",
            "Copied model parameters to target network.\n",
            "Episode 175: time   168; reward 1.0; epsilon: 0.9702; loss: 0.000012; @ global step 30070 with total reward 168.0\n",
            "Episode 176: time   202; reward 2.0; epsilon: 0.9700; loss: 0.000072; @ global step 30272 with total reward 170.0\n",
            "Episode 177: time   138; reward 0.0; epsilon: 0.9699; loss: 0.000029; @ global step 30410 with total reward 170.0\n",
            "Episode 178: time   163; reward 1.0; epsilon: 0.9697; loss: 0.000435; @ global step 30573 with total reward 171.0\n",
            "Episode 179: time   199; reward 2.0; epsilon: 0.9695; loss: 0.000091; @ global step 30772 with total reward 173.0\n",
            "Episode 180: time   170; reward 1.0; epsilon: 0.9694; loss: 0.000051; @ global step 30942 with total reward 174.0\n",
            "Episode 181: time   181; reward 1.0; epsilon: 0.9692; loss: 0.000184; @ global step 31123 with total reward 175.0\n",
            "Episode 182: time   188; reward 2.0; epsilon: 0.9690; loss: 0.000081; @ global step 31311 with total reward 177.0\n",
            "Episode 183: time   127; reward 0.0; epsilon: 0.9689; loss: 0.000015; @ global step 31438 with total reward 177.0\n",
            "Episode 184: time   183; reward 1.0; epsilon: 0.9687; loss: 0.003525; @ global step 31621 with total reward 178.0\n",
            "Episode 185: time   188; reward 1.0; epsilon: 0.9685; loss: 0.000047; @ global step 31809 with total reward 179.0\n",
            "Episode 186: time   212; reward 2.0; epsilon: 0.9683; loss: 0.000021; @ global step 32021 with total reward 181.0\n",
            "Episode 187: time   146; reward 0.0; epsilon: 0.9682; loss: 0.000261; @ global step 32167 with total reward 181.0\n",
            "Episode 188: time   185; reward 1.0; epsilon: 0.9680; loss: 0.000138; @ global step 32352 with total reward 182.0\n",
            "Episode 189: time   187; reward 1.0; epsilon: 0.9678; loss: 0.000029; @ global step 32539 with total reward 183.0\n",
            "Episode 190: time   221; reward 2.0; epsilon: 0.9676; loss: 0.000016; @ global step 32760 with total reward 185.0\n",
            "Episode 191: time   185; reward 1.0; epsilon: 0.9674; loss: 0.000010; @ global step 32945 with total reward 186.0\n",
            "Episode 192: time   139; reward 0.0; epsilon: 0.9672; loss: 0.000364; @ global step 33084 with total reward 186.0\n",
            "Episode 193: time   150; reward 0.0; epsilon: 0.9671; loss: 0.000052; @ global step 33234 with total reward 186.0\n",
            "Episode 194: time   170; reward 1.0; epsilon: 0.9669; loss: 0.000005; @ global step 33404 with total reward 187.0\n",
            "Episode 195: time   154; reward 1.0; epsilon: 0.9668; loss: 0.000004; @ global step 33558 with total reward 188.0\n",
            "Episode 196: time   138; reward 0.0; epsilon: 0.9666; loss: 0.000011; @ global step 33696 with total reward 188.0\n",
            "Episode 197: time   127; reward 0.0; epsilon: 0.9665; loss: 0.000037; @ global step 33823 with total reward 188.0\n",
            "Episode 198: time   232; reward 3.0; epsilon: 0.9663; loss: 0.000065; @ global step 34055 with total reward 191.0\n",
            "Episode 199: time   175; reward 1.0; epsilon: 0.9661; loss: 0.017143; @ global step 34230 with total reward 192.0\n",
            "Episode 200: time   137; reward 0.0; epsilon: 0.9660; loss: 0.000046; @ global step 34367 with total reward 192.0\n",
            "Episode 201: time   162; reward 1.0; epsilon: 0.9658; loss: 0.000015; @ global step 34529 with total reward 193.0\n",
            "Episode 202: time   213; reward 2.0; epsilon: 0.9656; loss: 0.000065; @ global step 34742 with total reward 195.0\n",
            "Episode 203: time   271; reward 3.0; epsilon: 0.9653; loss: 0.000008; @ global step 35013 with total reward 198.0\n",
            "Episode 204: time   135; reward 0.0; epsilon: 0.9652; loss: 0.000633; @ global step 35148 with total reward 198.0\n",
            "Episode 205: time   171; reward 1.0; epsilon: 0.9650; loss: 0.000120; @ global step 35319 with total reward 199.0\n",
            "Episode 206: time   211; reward 2.0; epsilon: 0.9648; loss: 0.000011; @ global step 35530 with total reward 201.0\n",
            "Episode 207: time   321; reward 4.0; epsilon: 0.9645; loss: 0.000002; @ global step 35851 with total reward 205.0\n",
            "Episode 208: time   158; reward 1.0; epsilon: 0.9644; loss: 0.000059; @ global step 36009 with total reward 206.0\n",
            "Episode 209: time   139; reward 0.0; epsilon: 0.9642; loss: 0.000010; @ global step 36148 with total reward 206.0\n",
            "Episode 210: time   142; reward 0.0; epsilon: 0.9641; loss: 0.000551; @ global step 36290 with total reward 206.0\n",
            "Episode 211: time   142; reward 0.0; epsilon: 0.9639; loss: 0.000100; @ global step 36432 with total reward 206.0\n",
            "Episode 212: time   193; reward 1.0; epsilon: 0.9637; loss: 0.000743; @ global step 36625 with total reward 207.0\n",
            "Episode 213: time   150; reward 0.0; epsilon: 0.9636; loss: 0.000012; @ global step 36775 with total reward 207.0\n",
            "Episode 214: time   159; reward 1.0; epsilon: 0.9634; loss: 0.000087; @ global step 36934 with total reward 208.0\n",
            "Episode 215: time   217; reward 2.0; epsilon: 0.9632; loss: 0.000006; @ global step 37151 with total reward 210.0\n",
            "Episode 216: time   270; reward 4.0; epsilon: 0.9630; loss: 0.000004; @ global step 37421 with total reward 214.0\n",
            "Episode 217: time   151; reward 0.0; epsilon: 0.9628; loss: 0.000147; @ global step 37572 with total reward 214.0\n",
            "Episode 218: time   267; reward 3.0; epsilon: 0.9625; loss: 0.005176; @ global step 37839 with total reward 217.0\n",
            "Episode 219: time   168; reward 1.0; epsilon: 0.9624; loss: 0.000264; @ global step 38007 with total reward 218.0\n",
            "Episode 220: time   132; reward 0.0; epsilon: 0.9622; loss: 0.000036; @ global step 38139 with total reward 218.0\n",
            "Episode 221: time   144; reward 0.0; epsilon: 0.9621; loss: 0.000022; @ global step 38283 with total reward 218.0\n",
            "Episode 222: time   209; reward 2.0; epsilon: 0.9619; loss: 0.000002; @ global step 38492 with total reward 220.0\n",
            "Episode 223: time   161; reward 1.0; epsilon: 0.9617; loss: 0.000001; @ global step 38653 with total reward 221.0\n",
            "Episode 224: time   232; reward 3.0; epsilon: 0.9615; loss: 0.000694; @ global step 38885 with total reward 224.0\n",
            "Episode 225: time   174; reward 1.0; epsilon: 0.9613; loss: 0.000003; @ global step 39059 with total reward 225.0\n",
            "Episode 226: time   136; reward 0.0; epsilon: 0.9612; loss: 0.000052; @ global step 39195 with total reward 225.0\n",
            "Episode 227: time   303; reward 4.0; epsilon: 0.9609; loss: 0.000002; @ global step 39498 with total reward 229.0\n",
            "Episode 228: time   133; reward 0.0; epsilon: 0.9608; loss: 0.000125; @ global step 39631 with total reward 229.0\n",
            "Episode 229: time   182; reward 1.0; epsilon: 0.9606; loss: 0.000011; @ global step 39813 with total reward 230.0\n",
            "Episode 230: time   177; reward 1.0; epsilon: 0.9604; loss: 0.000050; @ global step 39990 with total reward 231.0\n",
            "Episode 231: time    10; reward 0.0; epsilon: 0.9604; loss: 0.000015; @ global step 40000 with total reward 231.0\n",
            "Copied model parameters to target network.\n",
            "Episode 231: time   208; reward 2.0; epsilon: 0.9602; loss: 0.000012; @ global step 40198 with total reward 233.0\n",
            "Episode 232: time   165; reward 1.0; epsilon: 0.9600; loss: 0.007930; @ global step 40363 with total reward 234.0\n",
            "Episode 233: time   291; reward 4.0; epsilon: 0.9598; loss: 0.000211; @ global step 40654 with total reward 238.0\n",
            "Episode 234: time   132; reward 0.0; epsilon: 0.9596; loss: 0.000253; @ global step 40786 with total reward 238.0\n",
            "Episode 235: time   166; reward 1.0; epsilon: 0.9595; loss: 0.000187; @ global step 40952 with total reward 239.0\n",
            "Episode 236: time   153; reward 1.0; epsilon: 0.9593; loss: 0.000247; @ global step 41105 with total reward 240.0\n",
            "Episode 237: time   161; reward 1.0; epsilon: 0.9591; loss: 0.000214; @ global step 41266 with total reward 241.0\n",
            "Episode 238: time   144; reward 0.0; epsilon: 0.9590; loss: 0.000236; @ global step 41410 with total reward 241.0\n",
            "Episode 239: time   203; reward 1.0; epsilon: 0.9588; loss: 0.000225; @ global step 41613 with total reward 242.0\n",
            "Episode 240: time   212; reward 2.0; epsilon: 0.9586; loss: 0.004186; @ global step 41825 with total reward 244.0\n",
            "Episode 241: time   224; reward 2.0; epsilon: 0.9584; loss: 0.000593; @ global step 42049 with total reward 246.0\n",
            "Episode 242: time   159; reward 0.0; epsilon: 0.9582; loss: 0.000023; @ global step 42208 with total reward 246.0\n",
            "Episode 243: time   164; reward 1.0; epsilon: 0.9581; loss: 0.000085; @ global step 42372 with total reward 247.0\n",
            "Episode 244: time   145; reward 0.0; epsilon: 0.9579; loss: 0.000003; @ global step 42517 with total reward 247.0\n",
            "Episode 245: time   180; reward 1.0; epsilon: 0.9577; loss: 0.000006; @ global step 42697 with total reward 248.0\n",
            "Episode 246: time   135; reward 0.0; epsilon: 0.9576; loss: 0.000110; @ global step 42832 with total reward 248.0\n",
            "Episode 247: time   179; reward 1.0; epsilon: 0.9574; loss: 0.000013; @ global step 43011 with total reward 249.0\n",
            "Episode 248: time   175; reward 1.0; epsilon: 0.9572; loss: 0.000007; @ global step 43186 with total reward 250.0\n",
            "Episode 249: time   172; reward 1.0; epsilon: 0.9571; loss: 0.000060; @ global step 43358 with total reward 251.0\n",
            "Episode 250: time   209; reward 2.0; epsilon: 0.9569; loss: 0.000009; @ global step 43567 with total reward 253.0\n",
            "Episode 251: time   138; reward 0.0; epsilon: 0.9567; loss: 0.000040; @ global step 43705 with total reward 253.0\n",
            "Episode 252: time   155; reward 0.0; epsilon: 0.9566; loss: 0.000047; @ global step 43860 with total reward 253.0\n",
            "Episode 253: time   278; reward 4.0; epsilon: 0.9563; loss: 0.000324; @ global step 44138 with total reward 257.0\n",
            "Episode 254: time   134; reward 0.0; epsilon: 0.9562; loss: 0.000003; @ global step 44272 with total reward 257.0\n",
            "Episode 255: time   165; reward 0.0; epsilon: 0.9560; loss: 0.000005; @ global step 44437 with total reward 257.0\n",
            "Episode 256: time   182; reward 1.0; epsilon: 0.9558; loss: 0.000040; @ global step 44619 with total reward 258.0\n",
            "Episode 257: time   202; reward 2.0; epsilon: 0.9556; loss: 0.000003; @ global step 44821 with total reward 260.0\n",
            "Episode 258: time   153; reward 1.0; epsilon: 0.9555; loss: 0.000020; @ global step 44974 with total reward 261.0\n",
            "Episode 259: time   138; reward 0.0; epsilon: 0.9553; loss: 0.000203; @ global step 45112 with total reward 261.0\n",
            "Episode 260: time   153; reward 1.0; epsilon: 0.9552; loss: 0.000042; @ global step 45265 with total reward 262.0\n",
            "Episode 261: time   185; reward 1.0; epsilon: 0.9550; loss: 0.000007; @ global step 45450 with total reward 263.0\n",
            "Episode 262: time   304; reward 4.0; epsilon: 0.9547; loss: 0.000028; @ global step 45754 with total reward 267.0\n",
            "Episode 263: time   187; reward 2.0; epsilon: 0.9545; loss: 0.000006; @ global step 45941 with total reward 269.0\n",
            "Episode 264: time   138; reward 0.0; epsilon: 0.9544; loss: 0.000026; @ global step 46079 with total reward 269.0\n",
            "Episode 265: time   155; reward 1.0; epsilon: 0.9542; loss: 0.000013; @ global step 46234 with total reward 270.0\n",
            "Episode 266: time   140; reward 0.0; epsilon: 0.9541; loss: 0.000004; @ global step 46374 with total reward 270.0\n",
            "Episode 267: time   138; reward 0.0; epsilon: 0.9540; loss: 0.000123; @ global step 46512 with total reward 270.0\n",
            "Episode 268: time   220; reward 2.0; epsilon: 0.9537; loss: 0.000006; @ global step 46732 with total reward 272.0\n",
            "Episode 269: time   138; reward 0.0; epsilon: 0.9536; loss: 0.000173; @ global step 46870 with total reward 272.0\n",
            "Episode 270: time   136; reward 0.0; epsilon: 0.9535; loss: 0.000089; @ global step 47006 with total reward 272.0\n",
            "Episode 271: time   231; reward 2.0; epsilon: 0.9532; loss: 0.000002; @ global step 47237 with total reward 274.0\n",
            "Episode 272: time   200; reward 1.0; epsilon: 0.9530; loss: 0.000002; @ global step 47437 with total reward 275.0\n",
            "Episode 273: time   219; reward 2.0; epsilon: 0.9528; loss: 0.000008; @ global step 47656 with total reward 277.0\n",
            "Episode 274: time   143; reward 0.0; epsilon: 0.9527; loss: 0.000040; @ global step 47799 with total reward 277.0\n",
            "Episode 275: time   221; reward 2.0; epsilon: 0.9525; loss: 0.000048; @ global step 48020 with total reward 279.0\n",
            "Episode 276: time   234; reward 2.0; epsilon: 0.9522; loss: 0.000056; @ global step 48254 with total reward 281.0\n",
            "Episode 277: time   163; reward 1.0; epsilon: 0.9521; loss: 0.000003; @ global step 48417 with total reward 282.0\n",
            "Episode 278: time   152; reward 0.0; epsilon: 0.9519; loss: 0.000003; @ global step 48569 with total reward 282.0\n",
            "Episode 279: time   133; reward 0.0; epsilon: 0.9518; loss: 0.000096; @ global step 48702 with total reward 282.0\n",
            "Episode 280: time   226; reward 2.0; epsilon: 0.9516; loss: 0.000003; @ global step 48928 with total reward 284.0\n",
            "Episode 281: time   184; reward 1.0; epsilon: 0.9514; loss: 0.000023; @ global step 49112 with total reward 285.0\n",
            "Episode 282: time   184; reward 1.0; epsilon: 0.9512; loss: 0.000005; @ global step 49296 with total reward 286.0\n",
            "Episode 283: time   163; reward 1.0; epsilon: 0.9510; loss: 0.000581; @ global step 49459 with total reward 287.0\n",
            "Episode 284: time   176; reward 1.0; epsilon: 0.9509; loss: 0.000427; @ global step 49635 with total reward 288.0\n",
            "Episode 285: time   129; reward 0.0; epsilon: 0.9507; loss: 0.000309; @ global step 49764 with total reward 288.0\n",
            "Episode 286: time   123; reward 0.0; epsilon: 0.9506; loss: 0.000012; @ global step 49887 with total reward 288.0\n",
            "Episode 287: time   113; reward 1.0; epsilon: 0.9505; loss: 0.001805; @ global step 50000 with total reward 289.0\n",
            "Copied model parameters to target network.\n",
            "Episode 287: time   200; reward 2.0; epsilon: 0.9504; loss: 0.000255; @ global step 50087 with total reward 290.0\n",
            "Episode 288: time   193; reward 1.0; epsilon: 0.9502; loss: 0.000047; @ global step 50280 with total reward 291.0\n",
            "Episode 289: time   132; reward 0.0; epsilon: 0.9501; loss: 0.000007; @ global step 50412 with total reward 291.0\n",
            "Episode 290: time   130; reward 0.0; epsilon: 0.9500; loss: 0.000048; @ global step 50542 with total reward 291.0\n",
            "Episode 291: time   148; reward 0.0; epsilon: 0.9498; loss: 0.000037; @ global step 50690 with total reward 291.0\n",
            "Episode 292: time   212; reward 2.0; epsilon: 0.9496; loss: 0.000012; @ global step 50902 with total reward 293.0\n",
            "Episode 293: time   277; reward 3.0; epsilon: 0.9493; loss: 0.000025; @ global step 51179 with total reward 296.0\n",
            "Episode 294: time   196; reward 1.0; epsilon: 0.9491; loss: 0.000143; @ global step 51375 with total reward 297.0\n",
            "Episode 295: time   159; reward 1.0; epsilon: 0.9490; loss: 0.000103; @ global step 51534 with total reward 298.0\n",
            "Episode 296: time   211; reward 2.0; epsilon: 0.9488; loss: 0.000677; @ global step 51745 with total reward 300.0\n",
            "Episode 297: time   143; reward 0.0; epsilon: 0.9486; loss: 0.000069; @ global step 51888 with total reward 300.0\n",
            "Episode 298: time   210; reward 2.0; epsilon: 0.9484; loss: 0.000133; @ global step 52098 with total reward 302.0\n",
            "Episode 299: time   209; reward 2.0; epsilon: 0.9482; loss: 0.000002; @ global step 52307 with total reward 304.0\n",
            "Episode 300: time   138; reward 0.0; epsilon: 0.9481; loss: 0.000908; @ global step 52445 with total reward 304.0\n",
            "Episode 301: time   169; reward 1.0; epsilon: 0.9479; loss: 0.000008; @ global step 52614 with total reward 305.0\n",
            "Episode 302: time   174; reward 1.0; epsilon: 0.9477; loss: 0.000010; @ global step 52788 with total reward 306.0\n",
            "Episode 303: time   165; reward 1.0; epsilon: 0.9476; loss: 0.000007; @ global step 52953 with total reward 307.0\n",
            "Episode 304: time   172; reward 1.0; epsilon: 0.9474; loss: 0.000045; @ global step 53125 with total reward 308.0\n",
            "Episode 305: time   134; reward 0.0; epsilon: 0.9473; loss: 0.001804; @ global step 53259 with total reward 308.0\n",
            "Episode 306: time   129; reward 0.0; epsilon: 0.9471; loss: 0.000120; @ global step 53388 with total reward 308.0\n",
            "Episode 307: time   185; reward 1.0; epsilon: 0.9470; loss: 0.000004; @ global step 53573 with total reward 309.0\n",
            "Episode 308: time   170; reward 1.0; epsilon: 0.9468; loss: 0.000042; @ global step 53743 with total reward 310.0\n",
            "Episode 309: time   181; reward 1.0; epsilon: 0.9466; loss: 0.000063; @ global step 53924 with total reward 311.0\n",
            "Episode 310: time   192; reward 2.0; epsilon: 0.9464; loss: 0.000006; @ global step 54116 with total reward 313.0\n",
            "Episode 311: time   206; reward 2.0; epsilon: 0.9462; loss: 0.000016; @ global step 54322 with total reward 315.0\n",
            "Episode 312: time   221; reward 2.0; epsilon: 0.9460; loss: 0.000095; @ global step 54543 with total reward 317.0\n",
            "Episode 313: time   193; reward 2.0; epsilon: 0.9458; loss: 0.000042; @ global step 54736 with total reward 319.0\n",
            "Episode 314: time   135; reward 0.0; epsilon: 0.9457; loss: 0.000001; @ global step 54871 with total reward 319.0\n",
            "Episode 315: time   177; reward 1.0; epsilon: 0.9455; loss: 0.000235; @ global step 55048 with total reward 320.0\n",
            "Episode 316: time   134; reward 0.0; epsilon: 0.9454; loss: 0.000004; @ global step 55182 with total reward 320.0\n",
            "Episode 317: time   194; reward 2.0; epsilon: 0.9452; loss: 0.000022; @ global step 55376 with total reward 322.0\n",
            "Episode 318: time   136; reward 0.0; epsilon: 0.9450; loss: 0.000085; @ global step 55512 with total reward 322.0\n",
            "Episode 319: time   229; reward 2.0; epsilon: 0.9448; loss: 0.000001; @ global step 55741 with total reward 324.0\n",
            "Episode 320: time   136; reward 0.0; epsilon: 0.9447; loss: 0.000004; @ global step 55877 with total reward 324.0\n",
            "Episode 321: time   241; reward 3.0; epsilon: 0.9444; loss: 0.000089; @ global step 56118 with total reward 327.0\n",
            "Episode 322: time   151; reward 1.0; epsilon: 0.9443; loss: 0.000002; @ global step 56269 with total reward 328.0\n",
            "Episode 323: time   138; reward 0.0; epsilon: 0.9442; loss: 0.000006; @ global step 56407 with total reward 328.0\n",
            "Episode 324: time   190; reward 2.0; epsilon: 0.9440; loss: 0.000013; @ global step 56597 with total reward 330.0\n",
            "Episode 325: time   171; reward 1.0; epsilon: 0.9438; loss: 0.000115; @ global step 56768 with total reward 331.0\n",
            "Episode 326: time   171; reward 1.0; epsilon: 0.9436; loss: 0.000024; @ global step 56939 with total reward 332.0\n",
            "Episode 327: time   195; reward 1.0; epsilon: 0.9434; loss: 0.000207; @ global step 57134 with total reward 333.0\n",
            "Episode 328: time   236; reward 3.0; epsilon: 0.9432; loss: 0.000022; @ global step 57370 with total reward 336.0\n",
            "Episode 329: time   132; reward 0.0; epsilon: 0.9431; loss: 0.000057; @ global step 57502 with total reward 336.0\n",
            "Episode 330: time   200; reward 2.0; epsilon: 0.9429; loss: 0.000008; @ global step 57702 with total reward 338.0\n",
            "Episode 331: time   180; reward 1.0; epsilon: 0.9427; loss: 0.000151; @ global step 57882 with total reward 339.0\n",
            "Episode 332: time   169; reward 1.0; epsilon: 0.9425; loss: 0.000007; @ global step 58051 with total reward 340.0\n",
            "Episode 333: time   173; reward 1.0; epsilon: 0.9424; loss: 0.000001; @ global step 58224 with total reward 341.0\n",
            "Episode 334: time   141; reward 0.0; epsilon: 0.9422; loss: 0.000006; @ global step 58365 with total reward 341.0\n",
            "Episode 335: time   166; reward 1.0; epsilon: 0.9421; loss: 0.000019; @ global step 58531 with total reward 342.0\n",
            "Episode 336: time   214; reward 2.0; epsilon: 0.9418; loss: 0.000009; @ global step 58745 with total reward 344.0\n",
            "Episode 337: time   218; reward 2.0; epsilon: 0.9416; loss: 0.000030; @ global step 58963 with total reward 346.0\n",
            "Episode 338: time   210; reward 2.0; epsilon: 0.9414; loss: 0.000012; @ global step 59173 with total reward 348.0\n",
            "Episode 339: time   138; reward 0.0; epsilon: 0.9413; loss: 0.000012; @ global step 59311 with total reward 348.0\n",
            "Episode 340: time   174; reward 1.0; epsilon: 0.9411; loss: 0.000007; @ global step 59485 with total reward 349.0\n",
            "Episode 341: time   241; reward 2.0; epsilon: 0.9409; loss: 0.000044; @ global step 59726 with total reward 351.0\n",
            "Episode 342: time   168; reward 1.0; epsilon: 0.9407; loss: 0.000163; @ global step 59894 with total reward 352.0\n",
            "Episode 343: time   106; reward 2.0; epsilon: 0.9406; loss: 0.000021; @ global step 60000 with total reward 354.0WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "\n",
            "Copied model parameters to target network.\n",
            "Episode 343: time   268; reward 3.0; epsilon: 0.9404; loss: 0.000105; @ global step 60162 with total reward 355.0\n",
            "Episode 344: time   138; reward 0.0; epsilon: 0.9403; loss: 0.000309; @ global step 60300 with total reward 355.0\n",
            "Episode 345: time   176; reward 1.0; epsilon: 0.9401; loss: 0.000005; @ global step 60476 with total reward 356.0\n",
            "Episode 346: time   127; reward 0.0; epsilon: 0.9400; loss: 0.000025; @ global step 60603 with total reward 356.0\n",
            "Episode 347: time   129; reward 0.0; epsilon: 0.9399; loss: 0.000438; @ global step 60732 with total reward 356.0\n",
            "Episode 348: time   294; reward 3.0; epsilon: 0.9396; loss: 0.000033; @ global step 61026 with total reward 359.0\n",
            "Episode 349: time   167; reward 0.0; epsilon: 0.9394; loss: 0.000191; @ global step 61193 with total reward 359.0\n",
            "Episode 350: time   148; reward 0.0; epsilon: 0.9393; loss: 0.000094; @ global step 61341 with total reward 359.0\n",
            "Episode 351: time   133; reward 0.0; epsilon: 0.9391; loss: 0.000010; @ global step 61474 with total reward 359.0\n",
            "Episode 352: time   213; reward 2.0; epsilon: 0.9389; loss: 0.000038; @ global step 61687 with total reward 361.0\n",
            "Episode 353: time   220; reward 2.0; epsilon: 0.9387; loss: 0.000002; @ global step 61907 with total reward 363.0\n",
            "Episode 354: time   160; reward 1.0; epsilon: 0.9386; loss: 0.000163; @ global step 62067 with total reward 364.0\n",
            "Episode 355: time   163; reward 1.0; epsilon: 0.9384; loss: 0.000042; @ global step 62230 with total reward 365.0\n",
            "Episode 356: time   137; reward 0.0; epsilon: 0.9383; loss: 0.000099; @ global step 62367 with total reward 365.0\n",
            "Episode 357: time   190; reward 1.0; epsilon: 0.9381; loss: 0.000033; @ global step 62557 with total reward 366.0\n",
            "Episode 358: time   175; reward 1.0; epsilon: 0.9379; loss: 0.000019; @ global step 62732 with total reward 367.0\n",
            "Episode 359: time   212; reward 2.0; epsilon: 0.9377; loss: 0.000015; @ global step 62944 with total reward 369.0\n",
            "Episode 360: time   283; reward 3.0; epsilon: 0.9374; loss: 0.000006; @ global step 63227 with total reward 372.0\n",
            "Episode 361: time   173; reward 1.0; epsilon: 0.9372; loss: 0.000036; @ global step 63400 with total reward 373.0\n",
            "Episode 362: time   236; reward 3.0; epsilon: 0.9370; loss: 0.000002; @ global step 63636 with total reward 376.0\n",
            "Episode 363: time   178; reward 1.0; epsilon: 0.9368; loss: 0.000002; @ global step 63814 with total reward 377.0\n",
            "Episode 364: time   156; reward 1.0; epsilon: 0.9367; loss: 0.000008; @ global step 63970 with total reward 378.0\n",
            "Episode 365: time   131; reward 0.0; epsilon: 0.9365; loss: 0.000030; @ global step 64101 with total reward 378.0\n",
            "Episode 366: time   221; reward 2.0; epsilon: 0.9363; loss: 0.000237; @ global step 64322 with total reward 380.0\n",
            "Episode 367: time   135; reward 0.0; epsilon: 0.9362; loss: 0.000231; @ global step 64457 with total reward 380.0\n",
            "Episode 368: time   139; reward 0.0; epsilon: 0.9361; loss: 0.000024; @ global step 64596 with total reward 380.0\n",
            "Episode 369: time   213; reward 2.0; epsilon: 0.9358; loss: 0.000088; @ global step 64809 with total reward 382.0\n",
            "Episode 370: time   139; reward 0.0; epsilon: 0.9357; loss: 0.000074; @ global step 64948 with total reward 382.0\n",
            "Episode 371: time   142; reward 0.0; epsilon: 0.9356; loss: 0.000015; @ global step 65090 with total reward 382.0\n",
            "Episode 372: time   145; reward 0.0; epsilon: 0.9354; loss: 0.002354; @ global step 65235 with total reward 382.0\n",
            "Episode 373: time   264; reward 3.0; epsilon: 0.9352; loss: 0.000138; @ global step 65499 with total reward 385.0\n",
            "Episode 374: time   238; reward 2.0; epsilon: 0.9349; loss: 0.000009; @ global step 65737 with total reward 387.0\n",
            "Episode 375: time   214; reward 2.0; epsilon: 0.9347; loss: 0.000152; @ global step 65951 with total reward 389.0\n",
            "Episode 376: time   185; reward 1.0; epsilon: 0.9345; loss: 0.000025; @ global step 66136 with total reward 390.0\n",
            "Episode 377: time   220; reward 2.0; epsilon: 0.9343; loss: 0.000007; @ global step 66356 with total reward 392.0\n",
            "Episode 378: time   167; reward 1.0; epsilon: 0.9341; loss: 0.000185; @ global step 66523 with total reward 393.0\n",
            "Episode 379: time   141; reward 0.0; epsilon: 0.9340; loss: 0.000014; @ global step 66664 with total reward 393.0\n",
            "Episode 380: time   188; reward 1.0; epsilon: 0.9338; loss: 0.000057; @ global step 66852 with total reward 394.0\n",
            "Episode 381: time   128; reward 0.0; epsilon: 0.9337; loss: 0.000019; @ global step 66980 with total reward 394.0\n",
            "Episode 382: time   162; reward 1.0; epsilon: 0.9335; loss: 0.000851; @ global step 67142 with total reward 395.0\n",
            "Episode 383: time   138; reward 0.0; epsilon: 0.9334; loss: 0.000022; @ global step 67280 with total reward 395.0\n",
            "Episode 384: time   211; reward 2.0; epsilon: 0.9332; loss: 0.000007; @ global step 67491 with total reward 397.0\n",
            "Episode 385: time   232; reward 2.0; epsilon: 0.9330; loss: 0.000232; @ global step 67723 with total reward 399.0\n",
            "Episode 386: time   158; reward 1.0; epsilon: 0.9328; loss: 0.000054; @ global step 67881 with total reward 400.0\n",
            "Episode 387: time   160; reward 1.0; epsilon: 0.9326; loss: 0.000007; @ global step 68041 with total reward 401.0\n",
            "Episode 388: time   202; reward 2.0; epsilon: 0.9324; loss: 0.000003; @ global step 68243 with total reward 403.0\n",
            "Episode 389: time   134; reward 0.0; epsilon: 0.9323; loss: 0.000004; @ global step 68377 with total reward 403.0\n",
            "Episode 390: time   164; reward 1.0; epsilon: 0.9321; loss: 0.000008; @ global step 68541 with total reward 404.0\n",
            "Episode 391: time   132; reward 0.0; epsilon: 0.9320; loss: 0.000021; @ global step 68673 with total reward 404.0\n",
            "Episode 392: time   212; reward 2.0; epsilon: 0.9318; loss: 0.000143; @ global step 68885 with total reward 406.0\n",
            "Episode 393: time   201; reward 2.0; epsilon: 0.9316; loss: 0.000009; @ global step 69086 with total reward 408.0\n",
            "Episode 394: time   173; reward 1.0; epsilon: 0.9314; loss: 0.000010; @ global step 69259 with total reward 409.0\n",
            "Episode 395: time   174; reward 1.0; epsilon: 0.9313; loss: 0.000326; @ global step 69433 with total reward 410.0\n",
            "Episode 396: time   149; reward 0.0; epsilon: 0.9311; loss: 0.000007; @ global step 69582 with total reward 410.0\n",
            "Episode 397: time   151; reward 0.0; epsilon: 0.9310; loss: 0.000014; @ global step 69733 with total reward 410.0\n",
            "Episode 398: time   183; reward 1.0; epsilon: 0.9308; loss: 0.000003; @ global step 69916 with total reward 411.0\n",
            "Episode 399: time    84; reward 0.0; epsilon: 0.9307; loss: 0.000020; @ global step 70000 with total reward 411.0\n",
            "Copied model parameters to target network.\n",
            "Episode 399: time   230; reward 2.0; epsilon: 0.9306; loss: 0.000550; @ global step 70146 with total reward 413.0\n",
            "Episode 400: time   144; reward 0.0; epsilon: 0.9304; loss: 0.005794; @ global step 70290 with total reward 413.0\n",
            "Episode 401: time   173; reward 1.0; epsilon: 0.9302; loss: 0.000126; @ global step 70463 with total reward 414.0\n",
            "Episode 402: time   135; reward 0.0; epsilon: 0.9301; loss: 0.000101; @ global step 70598 with total reward 414.0\n",
            "Episode 403: time   185; reward 1.0; epsilon: 0.9299; loss: 0.000120; @ global step 70783 with total reward 415.0\n",
            "Episode 404: time   175; reward 1.0; epsilon: 0.9298; loss: 0.000070; @ global step 70958 with total reward 416.0\n",
            "Episode 405: time   126; reward 0.0; epsilon: 0.9296; loss: 0.000002; @ global step 71084 with total reward 416.0\n",
            "Episode 406: time   143; reward 0.0; epsilon: 0.9295; loss: 0.000042; @ global step 71227 with total reward 416.0\n",
            "Episode 407: time   202; reward 2.0; epsilon: 0.9293; loss: 0.000799; @ global step 71429 with total reward 418.0\n",
            "Episode 408: time   124; reward 0.0; epsilon: 0.9292; loss: 0.000079; @ global step 71553 with total reward 418.0\n",
            "Episode 409: time   159; reward 1.0; epsilon: 0.9290; loss: 0.001078; @ global step 71712 with total reward 419.0\n",
            "Episode 410: time   254; reward 3.0; epsilon: 0.9288; loss: 0.000023; @ global step 71966 with total reward 422.0\n",
            "Episode 411: time   155; reward 1.0; epsilon: 0.9286; loss: 0.000012; @ global step 72121 with total reward 423.0\n",
            "Episode 412: time   255; reward 3.0; epsilon: 0.9283; loss: 0.000026; @ global step 72376 with total reward 426.0\n",
            "Episode 413: time   188; reward 2.0; epsilon: 0.9282; loss: 0.000018; @ global step 72564 with total reward 428.0\n",
            "Episode 414: time   265; reward 3.0; epsilon: 0.9279; loss: 0.000107; @ global step 72829 with total reward 431.0\n",
            "Episode 415: time   187; reward 1.0; epsilon: 0.9277; loss: 0.000092; @ global step 73016 with total reward 432.0\n",
            "Episode 416: time   162; reward 1.0; epsilon: 0.9276; loss: 0.000138; @ global step 73178 with total reward 433.0\n",
            "Episode 417: time   217; reward 2.0; epsilon: 0.9273; loss: 0.000098; @ global step 73395 with total reward 435.0\n",
            "Episode 418: time   260; reward 3.0; epsilon: 0.9271; loss: 0.000015; @ global step 73655 with total reward 438.0\n",
            "Episode 419: time   140; reward 0.0; epsilon: 0.9269; loss: 0.000078; @ global step 73795 with total reward 438.0\n",
            "Episode 420: time   165; reward 1.0; epsilon: 0.9268; loss: 0.000047; @ global step 73960 with total reward 439.0\n",
            "Episode 421: time   133; reward 0.0; epsilon: 0.9266; loss: 0.000038; @ global step 74093 with total reward 439.0\n",
            "Episode 422: time   137; reward 0.0; epsilon: 0.9265; loss: 0.000284; @ global step 74230 with total reward 439.0\n",
            "Episode 423: time   139; reward 0.0; epsilon: 0.9264; loss: 0.000036; @ global step 74369 with total reward 439.0\n",
            "Episode 424: time   167; reward 1.0; epsilon: 0.9262; loss: 0.000012; @ global step 74536 with total reward 440.0\n",
            "Episode 425: time   159; reward 1.0; epsilon: 0.9261; loss: 0.000045; @ global step 74695 with total reward 441.0\n",
            "Episode 426: time   241; reward 3.0; epsilon: 0.9258; loss: 0.000021; @ global step 74936 with total reward 444.0\n",
            "Episode 427: time   140; reward 0.0; epsilon: 0.9257; loss: 0.000066; @ global step 75076 with total reward 444.0\n",
            "Episode 428: time   238; reward 3.0; epsilon: 0.9254; loss: 0.000251; @ global step 75314 with total reward 447.0\n",
            "Episode 429: time   137; reward 0.0; epsilon: 0.9253; loss: 0.000002; @ global step 75451 with total reward 447.0\n",
            "Episode 430: time   190; reward 2.0; epsilon: 0.9251; loss: 0.000044; @ global step 75641 with total reward 449.0\n",
            "Episode 431: time   188; reward 1.0; epsilon: 0.9249; loss: 0.000004; @ global step 75829 with total reward 450.0\n",
            "Episode 432: time   277; reward 3.0; epsilon: 0.9247; loss: 0.000012; @ global step 76106 with total reward 453.0\n",
            "Episode 433: time   132; reward 0.0; epsilon: 0.9245; loss: 0.000018; @ global step 76238 with total reward 453.0\n",
            "Episode 434: time   131; reward 0.0; epsilon: 0.9244; loss: 0.000072; @ global step 76369 with total reward 453.0\n",
            "Episode 435: time   174; reward 1.0; epsilon: 0.9242; loss: 0.000142; @ global step 76543 with total reward 454.0\n",
            "Episode 436: time   180; reward 1.0; epsilon: 0.9240; loss: 0.000005; @ global step 76723 with total reward 455.0\n",
            "Episode 437: time   150; reward 0.0; epsilon: 0.9239; loss: 0.000256; @ global step 76873 with total reward 455.0\n",
            "Episode 438: time   278; reward 3.0; epsilon: 0.9236; loss: 0.000037; @ global step 77151 with total reward 458.0\n",
            "Episode 439: time   262; reward 3.0; epsilon: 0.9234; loss: 0.000012; @ global step 77413 with total reward 461.0\n",
            "Episode 440: time   235; reward 2.0; epsilon: 0.9231; loss: 0.000690; @ global step 77648 with total reward 463.0\n",
            "Episode 441: time   175; reward 1.0; epsilon: 0.9230; loss: 0.000042; @ global step 77823 with total reward 464.0\n",
            "Episode 442: time   193; reward 1.0; epsilon: 0.9228; loss: 0.000040; @ global step 78016 with total reward 465.0\n",
            "Episode 443: time   181; reward 1.0; epsilon: 0.9226; loss: 0.000020; @ global step 78197 with total reward 466.0\n",
            "Episode 444: time   186; reward 1.0; epsilon: 0.9224; loss: 0.000003; @ global step 78383 with total reward 467.0\n",
            "Episode 445: time   213; reward 2.0; epsilon: 0.9222; loss: 0.000050; @ global step 78596 with total reward 469.0\n",
            "Episode 446: time   202; reward 2.0; epsilon: 0.9220; loss: 0.000010; @ global step 78798 with total reward 471.0\n",
            "Episode 447: time   180; reward 1.0; epsilon: 0.9218; loss: 0.000019; @ global step 78978 with total reward 472.0\n",
            "Episode 448: time   141; reward 0.0; epsilon: 0.9217; loss: 0.000032; @ global step 79119 with total reward 472.0\n",
            "Episode 449: time   188; reward 2.0; epsilon: 0.9215; loss: 0.000036; @ global step 79307 with total reward 474.0\n",
            "Episode 450: time   177; reward 1.0; epsilon: 0.9213; loss: 0.000046; @ global step 79484 with total reward 475.0\n",
            "Episode 451: time   208; reward 2.0; epsilon: 0.9211; loss: 0.000024; @ global step 79692 with total reward 477.0\n",
            "Episode 452: time   262; reward 3.0; epsilon: 0.9208; loss: 0.000043; @ global step 79954 with total reward 480.0\n",
            "Episode 453: time    46; reward 0.0; epsilon: 0.9208; loss: 0.000005; @ global step 80000 with total reward 480.0\n",
            "Copied model parameters to target network.\n",
            "Episode 453: time   206; reward 2.0; epsilon: 0.9206; loss: 0.000322; @ global step 80160 with total reward 482.0\n",
            "Episode 454: time   141; reward 0.0; epsilon: 0.9205; loss: 0.000290; @ global step 80301 with total reward 482.0\n",
            "Episode 455: time   182; reward 1.0; epsilon: 0.9203; loss: 0.000237; @ global step 80483 with total reward 483.0\n",
            "Episode 456: time   231; reward 3.0; epsilon: 0.9201; loss: 0.000043; @ global step 80714 with total reward 486.0\n",
            "Episode 457: time   131; reward 0.0; epsilon: 0.9200; loss: 0.000059; @ global step 80845 with total reward 486.0\n",
            "Episode 458: time   214; reward 2.0; epsilon: 0.9198; loss: 0.000090; @ global step 81059 with total reward 488.0\n",
            "Episode 459: time   135; reward 0.0; epsilon: 0.9196; loss: 0.000309; @ global step 81194 with total reward 488.0\n",
            "Episode 460: time   137; reward 0.0; epsilon: 0.9195; loss: 0.000138; @ global step 81331 with total reward 488.0\n",
            "Episode 461: time   175; reward 1.0; epsilon: 0.9193; loss: 0.000055; @ global step 81506 with total reward 489.0\n",
            "Episode 462: time   130; reward 0.0; epsilon: 0.9192; loss: 0.000053; @ global step 81636 with total reward 489.0\n",
            "Episode 463: time   136; reward 0.0; epsilon: 0.9190; loss: 0.000004; @ global step 81772 with total reward 489.0\n",
            "Episode 464: time   147; reward 0.0; epsilon: 0.9189; loss: 0.000050; @ global step 81919 with total reward 489.0\n",
            "Episode 465: time   135; reward 0.0; epsilon: 0.9188; loss: 0.000038; @ global step 82054 with total reward 489.0\n",
            "Episode 466: time   158; reward 0.0; epsilon: 0.9186; loss: 0.000802; @ global step 82212 with total reward 489.0\n",
            "Episode 467: time   147; reward 0.0; epsilon: 0.9185; loss: 0.000061; @ global step 82359 with total reward 489.0\n",
            "Episode 468: time   137; reward 0.0; epsilon: 0.9183; loss: 0.000006; @ global step 82496 with total reward 489.0\n",
            "Episode 469: time   163; reward 1.0; epsilon: 0.9182; loss: 0.000135; @ global step 82659 with total reward 490.0\n",
            "Episode 470: time   133; reward 0.0; epsilon: 0.9180; loss: 0.000010; @ global step 82792 with total reward 490.0\n",
            "Episode 471: time   178; reward 1.0; epsilon: 0.9179; loss: 0.000006; @ global step 82970 with total reward 491.0\n",
            "Episode 472: time   269; reward 4.0; epsilon: 0.9176; loss: 0.000042; @ global step 83239 with total reward 495.0\n",
            "Episode 473: time   128; reward 0.0; epsilon: 0.9175; loss: 0.000012; @ global step 83367 with total reward 495.0\n",
            "Episode 474: time   178; reward 1.0; epsilon: 0.9173; loss: 0.000002; @ global step 83545 with total reward 496.0\n",
            "Episode 475: time   130; reward 0.0; epsilon: 0.9172; loss: 0.000211; @ global step 83675 with total reward 496.0\n",
            "Episode 476: time   133; reward 0.0; epsilon: 0.9170; loss: 0.000453; @ global step 83808 with total reward 496.0\n",
            "Episode 477: time   139; reward 0.0; epsilon: 0.9169; loss: 0.017987; @ global step 83947 with total reward 496.0\n",
            "Episode 478: time   133; reward 0.0; epsilon: 0.9168; loss: 0.000005; @ global step 84080 with total reward 496.0\n",
            "Episode 479: time   136; reward 0.0; epsilon: 0.9166; loss: 0.000030; @ global step 84216 with total reward 496.0\n",
            "Episode 480: time   210; reward 2.0; epsilon: 0.9164; loss: 0.000323; @ global step 84426 with total reward 498.0\n",
            "Episode 481: time   133; reward 0.0; epsilon: 0.9163; loss: 0.000023; @ global step 84559 with total reward 498.0\n",
            "Episode 482: time   144; reward 0.0; epsilon: 0.9161; loss: 0.000067; @ global step 84703 with total reward 498.0\n",
            "Episode 483: time   247; reward 2.0; epsilon: 0.9159; loss: 0.000078; @ global step 84950 with total reward 500.0\n",
            "Episode 484: time   207; reward 2.0; epsilon: 0.9157; loss: 0.000026; @ global step 85157 with total reward 502.0\n",
            "Episode 485: time   139; reward 0.0; epsilon: 0.9156; loss: 0.000254; @ global step 85296 with total reward 502.0\n",
            "Episode 486: time   135; reward 0.0; epsilon: 0.9154; loss: 0.000051; @ global step 85431 with total reward 502.0\n",
            "Episode 487: time   233; reward 2.0; epsilon: 0.9152; loss: 0.000007; @ global step 85664 with total reward 504.0\n",
            "Episode 488: time   235; reward 2.0; epsilon: 0.9150; loss: 0.000200; @ global step 85899 with total reward 506.0\n",
            "Episode 489: time   139; reward 0.0; epsilon: 0.9148; loss: 0.000038; @ global step 86038 with total reward 506.0\n",
            "Episode 490: time   199; reward 2.0; epsilon: 0.9146; loss: 0.000024; @ global step 86237 with total reward 508.0\n",
            "Episode 491: time   180; reward 1.0; epsilon: 0.9144; loss: 0.000041; @ global step 86417 with total reward 509.0\n",
            "Episode 492: time   136; reward 0.0; epsilon: 0.9143; loss: 0.000006; @ global step 86553 with total reward 509.0\n",
            "Episode 493: time   161; reward 1.0; epsilon: 0.9142; loss: 0.000022; @ global step 86714 with total reward 510.0\n",
            "Episode 494: time   146; reward 0.0; epsilon: 0.9140; loss: 0.000046; @ global step 86860 with total reward 510.0\n",
            "Episode 495: time   254; reward 3.0; epsilon: 0.9138; loss: 0.000148; @ global step 87114 with total reward 513.0\n",
            "Episode 496: time   208; reward 2.0; epsilon: 0.9136; loss: 0.000089; @ global step 87322 with total reward 515.0\n",
            "Episode 497: time   254; reward 3.0; epsilon: 0.9133; loss: 0.000317; @ global step 87576 with total reward 518.0\n",
            "Episode 498: time   257; reward 3.0; epsilon: 0.9130; loss: 0.000042; @ global step 87833 with total reward 521.0\n",
            "Episode 499: time   148; reward 0.0; epsilon: 0.9129; loss: 0.000030; @ global step 87981 with total reward 521.0\n",
            "Episode 500: time   137; reward 0.0; epsilon: 0.9128; loss: 0.000018; @ global step 88118 with total reward 521.0\n",
            "Episode 501: time   204; reward 2.0; epsilon: 0.9126; loss: 0.000013; @ global step 88322 with total reward 523.0\n",
            "Episode 502: time   189; reward 2.0; epsilon: 0.9124; loss: 0.000017; @ global step 88511 with total reward 525.0\n",
            "Episode 503: time   175; reward 1.0; epsilon: 0.9122; loss: 0.000046; @ global step 88686 with total reward 526.0\n",
            "Episode 504: time   145; reward 0.0; epsilon: 0.9121; loss: 0.000013; @ global step 88831 with total reward 526.0\n",
            "Episode 505: time   164; reward 1.0; epsilon: 0.9119; loss: 0.000021; @ global step 88995 with total reward 527.0\n",
            "Episode 506: time   138; reward 0.0; epsilon: 0.9118; loss: 0.000082; @ global step 89133 with total reward 527.0\n",
            "Episode 507: time   137; reward 0.0; epsilon: 0.9116; loss: 0.000067; @ global step 89270 with total reward 527.0\n",
            "Episode 508: time   205; reward 2.0; epsilon: 0.9114; loss: 0.000001; @ global step 89475 with total reward 529.0\n",
            "Episode 509: time   165; reward 1.0; epsilon: 0.9113; loss: 0.000036; @ global step 89640 with total reward 530.0\n",
            "Episode 510: time   334; reward 6.0; epsilon: 0.9109; loss: 0.000034; @ global step 89974 with total reward 536.0\n",
            "Episode 511: time    26; reward 0.0; epsilon: 0.9109; loss: 0.000079; @ global step 90000 with total reward 536.0\n",
            "Copied model parameters to target network.\n",
            "Episode 511: time   201; reward 2.0; epsilon: 0.9107; loss: 0.000226; @ global step 90175 with total reward 538.0\n",
            "Episode 512: time   179; reward 1.0; epsilon: 0.9106; loss: 0.000072; @ global step 90354 with total reward 539.0\n",
            "Episode 513: time   202; reward 2.0; epsilon: 0.9104; loss: 0.000094; @ global step 90556 with total reward 541.0\n",
            "Episode 514: time   162; reward 1.0; epsilon: 0.9102; loss: 0.000060; @ global step 90718 with total reward 542.0\n",
            "Episode 515: time   193; reward 2.0; epsilon: 0.9100; loss: 0.000100; @ global step 90911 with total reward 544.0\n",
            "Episode 516: time   204; reward 2.0; epsilon: 0.9098; loss: 0.000166; @ global step 91115 with total reward 546.0\n",
            "Episode 517: time   173; reward 1.0; epsilon: 0.9096; loss: 0.000006; @ global step 91288 with total reward 547.0\n",
            "Episode 518: time   284; reward 3.0; epsilon: 0.9093; loss: 0.000231; @ global step 91572 with total reward 550.0\n",
            "Episode 519: time   175; reward 1.0; epsilon: 0.9092; loss: 0.000049; @ global step 91747 with total reward 551.0\n",
            "Episode 520: time   159; reward 1.0; epsilon: 0.9090; loss: 0.000110; @ global step 91906 with total reward 552.0\n",
            "Episode 521: time   134; reward 0.0; epsilon: 0.9089; loss: 0.000026; @ global step 92040 with total reward 552.0\n",
            "Episode 522: time   208; reward 2.0; epsilon: 0.9087; loss: 0.000026; @ global step 92248 with total reward 554.0\n",
            "Episode 523: time   139; reward 0.0; epsilon: 0.9085; loss: 0.000034; @ global step 92387 with total reward 554.0\n",
            "Episode 524: time   137; reward 0.0; epsilon: 0.9084; loss: 0.000069; @ global step 92524 with total reward 554.0\n",
            "Episode 525: time   238; reward 3.0; epsilon: 0.9082; loss: 0.000005; @ global step 92762 with total reward 557.0\n",
            "Episode 526: time   191; reward 2.0; epsilon: 0.9080; loss: 0.000043; @ global step 92953 with total reward 559.0\n",
            "Episode 527: time   227; reward 2.0; epsilon: 0.9078; loss: 0.000107; @ global step 93180 with total reward 561.0\n",
            "Episode 528: time   135; reward 0.0; epsilon: 0.9076; loss: 0.000006; @ global step 93315 with total reward 561.0\n",
            "Episode 529: time   200; reward 1.0; epsilon: 0.9074; loss: 0.000009; @ global step 93515 with total reward 562.0\n",
            "Episode 530: time   166; reward 1.0; epsilon: 0.9073; loss: 0.000023; @ global step 93681 with total reward 563.0\n",
            "Episode 531: time   378; reward 5.0; epsilon: 0.9069; loss: 0.000372; @ global step 94059 with total reward 568.0\n",
            "Episode 532: time   201; reward 1.0; epsilon: 0.9067; loss: 0.000023; @ global step 94260 with total reward 569.0\n",
            "Episode 533: time   272; reward 4.0; epsilon: 0.9064; loss: 0.000028; @ global step 94532 with total reward 573.0\n",
            "Episode 534: time   161; reward 1.0; epsilon: 0.9063; loss: 0.000027; @ global step 94693 with total reward 574.0\n",
            "Episode 535: time   146; reward 0.0; epsilon: 0.9061; loss: 0.000042; @ global step 94839 with total reward 574.0\n",
            "Episode 536: time   217; reward 2.0; epsilon: 0.9059; loss: 0.000045; @ global step 95056 with total reward 576.0\n",
            "Episode 537: time   128; reward 0.0; epsilon: 0.9058; loss: 0.000060; @ global step 95184 with total reward 576.0\n",
            "Episode 538: time   177; reward 1.0; epsilon: 0.9056; loss: 0.000075; @ global step 95361 with total reward 577.0\n",
            "Episode 539: time   175; reward 1.0; epsilon: 0.9054; loss: 0.000011; @ global step 95536 with total reward 578.0\n",
            "Episode 540: time   331; reward 5.0; epsilon: 0.9051; loss: 0.000003; @ global step 95867 with total reward 583.0\n",
            "Episode 541: time   125; reward 0.0; epsilon: 0.9050; loss: 0.000031; @ global step 95992 with total reward 583.0\n",
            "Episode 542: time   230; reward 2.0; epsilon: 0.9047; loss: 0.000130; @ global step 96222 with total reward 585.0\n",
            "Episode 543: time   142; reward 0.0; epsilon: 0.9046; loss: 0.000045; @ global step 96364 with total reward 585.0\n",
            "Episode 544: time   193; reward 1.0; epsilon: 0.9044; loss: 0.000047; @ global step 96557 with total reward 586.0\n",
            "Episode 545: time   234; reward 3.0; epsilon: 0.9042; loss: 0.000028; @ global step 96791 with total reward 589.0\n",
            "Episode 546: time   135; reward 0.0; epsilon: 0.9040; loss: 0.000181; @ global step 96926 with total reward 589.0\n",
            "Episode 547: time   189; reward 1.0; epsilon: 0.9039; loss: 0.000020; @ global step 97115 with total reward 590.0\n",
            "Episode 548: time   167; reward 1.0; epsilon: 0.9037; loss: 0.000015; @ global step 97282 with total reward 591.0\n",
            "Episode 549: time   159; reward 1.0; epsilon: 0.9035; loss: 0.000030; @ global step 97441 with total reward 592.0\n",
            "Episode 550: time   224; reward 2.0; epsilon: 0.9033; loss: 0.000038; @ global step 97665 with total reward 594.0\n",
            "Episode 551: time   191; reward 2.0; epsilon: 0.9031; loss: 0.000017; @ global step 97856 with total reward 596.0\n",
            "Episode 552: time   207; reward 2.0; epsilon: 0.9029; loss: 0.000097; @ global step 98063 with total reward 598.0\n",
            "Episode 553: time   192; reward 2.0; epsilon: 0.9027; loss: 0.000027; @ global step 98255 with total reward 600.0\n",
            "Episode 554: time   150; reward 0.0; epsilon: 0.9026; loss: 0.000017; @ global step 98405 with total reward 600.0\n",
            "Episode 555: time   157; reward 1.0; epsilon: 0.9024; loss: 0.000022; @ global step 98562 with total reward 601.0\n",
            "Episode 556: time   218; reward 2.0; epsilon: 0.9022; loss: 0.000020; @ global step 98780 with total reward 603.0\n",
            "Episode 557: time   168; reward 1.0; epsilon: 0.9020; loss: 0.000137; @ global step 98948 with total reward 604.0\n",
            "Episode 558: time   210; reward 2.0; epsilon: 0.9018; loss: 0.000028; @ global step 99158 with total reward 606.0\n",
            "Episode 559: time   135; reward 0.0; epsilon: 0.9017; loss: 0.000130; @ global step 99293 with total reward 606.0\n",
            "Episode 560: time   180; reward 1.0; epsilon: 0.9015; loss: 0.000038; @ global step 99473 with total reward 607.0\n",
            "Episode 561: time   225; reward 2.0; epsilon: 0.9013; loss: 0.000157; @ global step 99698 with total reward 609.0\n",
            "Episode 562: time   170; reward 1.0; epsilon: 0.9011; loss: 0.000119; @ global step 99868 with total reward 610.0\n",
            "Episode 563: time   132; reward 0.0; epsilon: 0.9010; loss: 0.000082; @ global step 100000 with total reward 610.0\n",
            "Copied model parameters to target network.\n",
            "Episode 563: time   133; reward 0.0; epsilon: 0.9010; loss: 0.000010; @ global step 100001 with total reward 610.0\n",
            "Episode 564: time   136; reward 0.0; epsilon: 0.9009; loss: 0.000412; @ global step 100137 with total reward 610.0\n",
            "Episode 565: time   144; reward 0.0; epsilon: 0.9007; loss: 0.001704; @ global step 100281 with total reward 610.0\n",
            "Episode 566: time   135; reward 0.0; epsilon: 0.9006; loss: 0.000229; @ global step 100416 with total reward 610.0\n",
            "Episode 567: time   214; reward 2.0; epsilon: 0.9004; loss: 0.000018; @ global step 100630 with total reward 612.0\n",
            "Episode 568: time   138; reward 0.0; epsilon: 0.9002; loss: 0.000284; @ global step 100768 with total reward 612.0\n",
            "Episode 569: time   270; reward 4.0; epsilon: 0.9000; loss: 0.000036; @ global step 101038 with total reward 616.0\n",
            "Episode 570: time   171; reward 1.0; epsilon: 0.8998; loss: 0.000009; @ global step 101209 with total reward 617.0\n",
            "Episode 571: time   175; reward 1.0; epsilon: 0.8996; loss: 0.000007; @ global step 101384 with total reward 618.0\n",
            "Episode 572: time   176; reward 1.0; epsilon: 0.8995; loss: 0.000844; @ global step 101560 with total reward 619.0\n",
            "Episode 573: time   191; reward 2.0; epsilon: 0.8993; loss: 0.000027; @ global step 101751 with total reward 621.0\n",
            "Episode 574: time   128; reward 0.0; epsilon: 0.8991; loss: 0.000051; @ global step 101879 with total reward 621.0\n",
            "Episode 575: time   174; reward 1.0; epsilon: 0.8990; loss: 0.000060; @ global step 102053 with total reward 622.0\n",
            "Episode 576: time   291; reward 4.0; epsilon: 0.8987; loss: 0.000042; @ global step 102344 with total reward 626.0\n",
            "Episode 577: time   162; reward 1.0; epsilon: 0.8985; loss: 0.000295; @ global step 102506 with total reward 627.0\n",
            "Episode 578: time   311; reward 8.0; epsilon: 0.8982; loss: 0.000015; @ global step 102817 with total reward 635.0\n",
            "Episode 579: time   128; reward 0.0; epsilon: 0.8981; loss: 0.000058; @ global step 102945 with total reward 635.0\n",
            "Episode 580: time   206; reward 1.0; epsilon: 0.8979; loss: 0.000027; @ global step 103151 with total reward 636.0\n",
            "Episode 581: time   212; reward 2.0; epsilon: 0.8977; loss: 0.000034; @ global step 103363 with total reward 638.0\n",
            "Episode 582: time   130; reward 0.0; epsilon: 0.8975; loss: 0.000036; @ global step 103493 with total reward 638.0\n",
            "Episode 583: time   184; reward 1.0; epsilon: 0.8974; loss: 0.000109; @ global step 103677 with total reward 639.0\n",
            "Episode 584: time   144; reward 0.0; epsilon: 0.8972; loss: 0.000178; @ global step 103821 with total reward 639.0\n",
            "Episode 585: time   124; reward 0.0; epsilon: 0.8971; loss: 0.000018; @ global step 103945 with total reward 639.0\n",
            "Episode 586: time   203; reward 2.0; epsilon: 0.8969; loss: 0.000193; @ global step 104148 with total reward 641.0\n",
            "Episode 587: time   186; reward 2.0; epsilon: 0.8967; loss: 0.000146; @ global step 104334 with total reward 643.0\n",
            "Episode 588: time   130; reward 0.0; epsilon: 0.8966; loss: 0.000018; @ global step 104464 with total reward 643.0\n",
            "Episode 589: time   142; reward 0.0; epsilon: 0.8964; loss: 0.000027; @ global step 104606 with total reward 643.0\n",
            "Episode 590: time   224; reward 2.0; epsilon: 0.8962; loss: 0.000045; @ global step 104830 with total reward 645.0\n",
            "Episode 591: time   213; reward 2.0; epsilon: 0.8960; loss: 0.000010; @ global step 105043 with total reward 647.0\n",
            "Episode 592: time   206; reward 2.0; epsilon: 0.8958; loss: 0.000185; @ global step 105249 with total reward 649.0\n",
            "Episode 593: time   187; reward 1.0; epsilon: 0.8956; loss: 0.002228; @ global step 105436 with total reward 650.0\n",
            "Episode 594: time   206; reward 2.0; epsilon: 0.8954; loss: 0.000100; @ global step 105642 with total reward 652.0\n",
            "Episode 595: time   132; reward 0.0; epsilon: 0.8953; loss: 0.000037; @ global step 105774 with total reward 652.0\n",
            "Episode 596: time   136; reward 0.0; epsilon: 0.8952; loss: 0.000187; @ global step 105910 with total reward 652.0\n",
            "Episode 597: time   250; reward 3.0; epsilon: 0.8949; loss: 0.000032; @ global step 106160 with total reward 655.0\n",
            "Episode 598: time   133; reward 0.0; epsilon: 0.8948; loss: 0.000021; @ global step 106293 with total reward 655.0\n",
            "Episode 599: time   335; reward 5.0; epsilon: 0.8944; loss: 0.000024; @ global step 106628 with total reward 660.0\n",
            "Episode 600: time   133; reward 0.0; epsilon: 0.8943; loss: 0.000006; @ global step 106761 with total reward 660.0\n",
            "Episode 601: time   147; reward 0.0; epsilon: 0.8942; loss: 0.000006; @ global step 106908 with total reward 660.0\n",
            "Episode 602: time   175; reward 1.0; epsilon: 0.8940; loss: 0.000084; @ global step 107083 with total reward 661.0\n",
            "Episode 603: time   134; reward 0.0; epsilon: 0.8939; loss: 0.000008; @ global step 107217 with total reward 661.0\n",
            "Episode 604: time   277; reward 3.0; epsilon: 0.8936; loss: 0.000016; @ global step 107494 with total reward 664.0\n",
            "Episode 605: time   129; reward 0.0; epsilon: 0.8935; loss: 0.000013; @ global step 107623 with total reward 664.0\n",
            "Episode 606: time   147; reward 0.0; epsilon: 0.8933; loss: 0.000009; @ global step 107770 with total reward 664.0\n",
            "Episode 607: time   223; reward 3.0; epsilon: 0.8931; loss: 0.000005; @ global step 107993 with total reward 667.0\n",
            "Episode 608: time   134; reward 0.0; epsilon: 0.8930; loss: 0.000009; @ global step 108127 with total reward 667.0\n",
            "Episode 609: time   178; reward 1.0; epsilon: 0.8928; loss: 0.000003; @ global step 108305 with total reward 668.0\n",
            "Episode 610: time   135; reward 0.0; epsilon: 0.8926; loss: 0.000029; @ global step 108440 with total reward 668.0\n",
            "Episode 611: time   189; reward 2.0; epsilon: 0.8925; loss: 0.000031; @ global step 108629 with total reward 670.0\n",
            "Episode 612: time   237; reward 3.0; epsilon: 0.8922; loss: 0.000007; @ global step 108866 with total reward 673.0\n",
            "Episode 613: time   182; reward 1.0; epsilon: 0.8920; loss: 0.000028; @ global step 109048 with total reward 674.0\n",
            "Episode 614: time   170; reward 1.0; epsilon: 0.8919; loss: 0.000345; @ global step 109218 with total reward 675.0\n",
            "Episode 615: time   176; reward 1.0; epsilon: 0.8917; loss: 0.000039; @ global step 109394 with total reward 676.0\n",
            "Episode 616: time   206; reward 2.0; epsilon: 0.8915; loss: 0.000040; @ global step 109600 with total reward 678.0\n",
            "Episode 617: time   283; reward 3.0; epsilon: 0.8912; loss: 0.000010; @ global step 109883 with total reward 681.0\n",
            "Episode 618: time   117; reward 0.0; epsilon: 0.8911; loss: 0.000006; @ global step 110000 with total reward 681.0\n",
            "Copied model parameters to target network.\n",
            "Episode 618: time   136; reward 0.0; epsilon: 0.8911; loss: 0.000412; @ global step 110019 with total reward 681.0\n",
            "Episode 619: time   160; reward 1.0; epsilon: 0.8909; loss: 0.001936; @ global step 110179 with total reward 682.0\n",
            "Episode 620: time   254; reward 3.0; epsilon: 0.8907; loss: 0.002549; @ global step 110433 with total reward 685.0\n",
            "Episode 621: time   140; reward 0.0; epsilon: 0.8905; loss: 0.000089; @ global step 110573 with total reward 685.0\n",
            "Episode 622: time   275; reward 3.0; epsilon: 0.8903; loss: 0.000012; @ global step 110848 with total reward 688.0\n",
            "Episode 623: time   135; reward 0.0; epsilon: 0.8901; loss: 0.000145; @ global step 110983 with total reward 688.0\n",
            "Episode 624: time   261; reward 4.0; epsilon: 0.8899; loss: 0.000096; @ global step 111244 with total reward 692.0\n",
            "Episode 625: time   219; reward 2.0; epsilon: 0.8897; loss: 0.000032; @ global step 111463 with total reward 694.0\n",
            "Episode 626: time   225; reward 2.0; epsilon: 0.8894; loss: 0.001126; @ global step 111688 with total reward 696.0\n",
            "Episode 627: time   207; reward 2.0; epsilon: 0.8892; loss: 0.000367; @ global step 111895 with total reward 698.0\n",
            "Episode 628: time   169; reward 1.0; epsilon: 0.8891; loss: 0.001243; @ global step 112064 with total reward 699.0\n",
            "Episode 629: time   179; reward 1.0; epsilon: 0.8889; loss: 0.000135; @ global step 112243 with total reward 700.0\n",
            "Episode 630: time   142; reward 0.0; epsilon: 0.8887; loss: 0.001979; @ global step 112385 with total reward 700.0\n",
            "Episode 631: time   163; reward 1.0; epsilon: 0.8886; loss: 0.000039; @ global step 112548 with total reward 701.0\n",
            "Episode 632: time   204; reward 2.0; epsilon: 0.8884; loss: 0.000119; @ global step 112752 with total reward 703.0\n",
            "Episode 633: time   132; reward 0.0; epsilon: 0.8882; loss: 0.000039; @ global step 112884 with total reward 703.0\n",
            "Episode 634: time   282; reward 4.0; epsilon: 0.8880; loss: 0.000066; @ global step 113166 with total reward 707.0\n",
            "Episode 635: time   134; reward 0.0; epsilon: 0.8878; loss: 0.000095; @ global step 113300 with total reward 707.0\n",
            "Episode 636: time   172; reward 1.0; epsilon: 0.8877; loss: 0.000016; @ global step 113472 with total reward 708.0\n",
            "Episode 637: time   273; reward 3.0; epsilon: 0.8874; loss: 0.000309; @ global step 113745 with total reward 711.0\n",
            "Episode 638: time   178; reward 1.0; epsilon: 0.8872; loss: 0.000024; @ global step 113923 with total reward 712.0\n",
            "Episode 639: time   177; reward 1.0; epsilon: 0.8870; loss: 0.000112; @ global step 114100 with total reward 713.0\n",
            "Episode 640: time   143; reward 0.0; epsilon: 0.8869; loss: 0.000159; @ global step 114243 with total reward 713.0\n",
            "Episode 641: time   200; reward 2.0; epsilon: 0.8867; loss: 0.000008; @ global step 114443 with total reward 715.0\n",
            "Episode 642: time   176; reward 1.0; epsilon: 0.8865; loss: 0.000011; @ global step 114619 with total reward 716.0\n",
            "Episode 643: time   166; reward 1.0; epsilon: 0.8864; loss: 0.000534; @ global step 114785 with total reward 717.0\n",
            "Episode 644: time   136; reward 0.0; epsilon: 0.8862; loss: 0.000023; @ global step 114921 with total reward 717.0\n",
            "Episode 645: time   147; reward 0.0; epsilon: 0.8861; loss: 0.000032; @ global step 115068 with total reward 717.0\n",
            "Episode 646: time   215; reward 2.0; epsilon: 0.8859; loss: 0.000015; @ global step 115283 with total reward 719.0\n",
            "Episode 647: time   136; reward 0.0; epsilon: 0.8857; loss: 0.000093; @ global step 115419 with total reward 719.0\n",
            "Episode 648: time   259; reward 3.0; epsilon: 0.8855; loss: 0.000039; @ global step 115678 with total reward 722.0\n",
            "Episode 649: time   175; reward 1.0; epsilon: 0.8853; loss: 0.000343; @ global step 115853 with total reward 723.0\n",
            "Episode 650: time   137; reward 0.0; epsilon: 0.8852; loss: 0.000128; @ global step 115990 with total reward 723.0\n",
            "Episode 651: time   158; reward 1.0; epsilon: 0.8850; loss: 0.000026; @ global step 116148 with total reward 724.0\n",
            "Episode 652: time   176; reward 1.0; epsilon: 0.8848; loss: 0.000064; @ global step 116324 with total reward 725.0\n",
            "Episode 653: time   249; reward 2.0; epsilon: 0.8846; loss: 0.000011; @ global step 116573 with total reward 727.0\n",
            "Episode 654: time   141; reward 0.0; epsilon: 0.8845; loss: 0.000050; @ global step 116714 with total reward 727.0\n",
            "Episode 655: time   139; reward 0.0; epsilon: 0.8843; loss: 0.000043; @ global step 116853 with total reward 727.0\n",
            "Episode 656: time   208; reward 2.0; epsilon: 0.8841; loss: 0.000032; @ global step 117061 with total reward 729.0\n",
            "Episode 657: time   269; reward 3.0; epsilon: 0.8838; loss: 0.000043; @ global step 117330 with total reward 732.0\n",
            "Episode 658: time   247; reward 3.0; epsilon: 0.8836; loss: 0.000006; @ global step 117577 with total reward 735.0\n",
            "Episode 659: time   169; reward 1.0; epsilon: 0.8834; loss: 0.000040; @ global step 117746 with total reward 736.0\n",
            "Episode 660: time   191; reward 2.0; epsilon: 0.8832; loss: 0.000172; @ global step 117937 with total reward 738.0\n",
            "Episode 661: time   170; reward 1.0; epsilon: 0.8831; loss: 0.000036; @ global step 118107 with total reward 739.0\n",
            "Episode 662: time   216; reward 2.0; epsilon: 0.8829; loss: 0.000014; @ global step 118323 with total reward 741.0\n",
            "Episode 663: time   156; reward 1.0; epsilon: 0.8827; loss: 0.000164; @ global step 118479 with total reward 742.0\n",
            "Episode 664: time   168; reward 0.0; epsilon: 0.8825; loss: 0.000018; @ global step 118647 with total reward 742.0\n",
            "Episode 665: time   155; reward 1.0; epsilon: 0.8824; loss: 0.000044; @ global step 118802 with total reward 743.0\n",
            "Episode 666: time   159; reward 1.0; epsilon: 0.8822; loss: 0.000026; @ global step 118961 with total reward 744.0\n",
            "Episode 667: time   162; reward 0.0; epsilon: 0.8821; loss: 0.000231; @ global step 119123 with total reward 744.0\n",
            "Episode 668: time   132; reward 0.0; epsilon: 0.8819; loss: 0.000013; @ global step 119255 with total reward 744.0\n",
            "Episode 669: time   189; reward 2.0; epsilon: 0.8818; loss: 0.000160; @ global step 119444 with total reward 746.0\n",
            "Episode 670: time   277; reward 4.0; epsilon: 0.8815; loss: 0.000016; @ global step 119721 with total reward 750.0\n",
            "Episode 671: time   261; reward 3.0; epsilon: 0.8812; loss: 0.000109; @ global step 119982 with total reward 753.0\n",
            "Episode 672: time    18; reward 0.0; epsilon: 0.8812; loss: 0.000016; @ global step 120000 with total reward 753.0\n",
            "Copied model parameters to target network.\n",
            "Episode 672: time   205; reward 2.0; epsilon: 0.8810; loss: 0.000038; @ global step 120187 with total reward 755.0\n",
            "Episode 673: time   190; reward 1.0; epsilon: 0.8808; loss: 0.000049; @ global step 120377 with total reward 756.0\n",
            "Episode 674: time   232; reward 2.0; epsilon: 0.8806; loss: 0.000026; @ global step 120609 with total reward 758.0\n",
            "Episode 675: time   135; reward 0.0; epsilon: 0.8805; loss: 0.000219; @ global step 120744 with total reward 758.0\n",
            "Episode 676: time   127; reward 0.0; epsilon: 0.8803; loss: 0.000168; @ global step 120871 with total reward 758.0\n",
            "Episode 677: time   141; reward 0.0; epsilon: 0.8802; loss: 0.000120; @ global step 121012 with total reward 758.0\n",
            "Episode 678: time   169; reward 1.0; epsilon: 0.8800; loss: 0.000363; @ global step 121181 with total reward 759.0\n",
            "Episode 679: time   159; reward 1.0; epsilon: 0.8799; loss: 0.003981; @ global step 121340 with total reward 760.0\n",
            "Episode 680: time   130; reward 0.0; epsilon: 0.8797; loss: 0.000195; @ global step 121470 with total reward 760.0\n",
            "Episode 681: time   221; reward 3.0; epsilon: 0.8795; loss: 0.000020; @ global step 121691 with total reward 763.0\n",
            "Episode 682: time   165; reward 0.0; epsilon: 0.8794; loss: 0.000028; @ global step 121856 with total reward 763.0\n",
            "Episode 683: time   186; reward 1.0; epsilon: 0.8792; loss: 0.000032; @ global step 122042 with total reward 764.0\n",
            "Episode 684: time   188; reward 1.0; epsilon: 0.8790; loss: 0.000014; @ global step 122230 with total reward 765.0\n",
            "Episode 685: time   183; reward 1.0; epsilon: 0.8788; loss: 0.000034; @ global step 122413 with total reward 766.0\n",
            "Episode 686: time   159; reward 1.0; epsilon: 0.8787; loss: 0.000053; @ global step 122572 with total reward 767.0\n",
            "Episode 687: time   143; reward 0.0; epsilon: 0.8785; loss: 0.000022; @ global step 122715 with total reward 767.0\n",
            "Episode 688: time   124; reward 0.0; epsilon: 0.8784; loss: 0.000048; @ global step 122839 with total reward 767.0\n",
            "Episode 689: time   221; reward 2.0; epsilon: 0.8782; loss: 0.000074; @ global step 123060 with total reward 769.0\n",
            "Episode 690: time   175; reward 1.0; epsilon: 0.8780; loss: 0.000701; @ global step 123235 with total reward 770.0\n",
            "Episode 691: time   164; reward 1.0; epsilon: 0.8778; loss: 0.001023; @ global step 123399 with total reward 771.0\n",
            "Episode 692: time   187; reward 2.0; epsilon: 0.8777; loss: 0.000056; @ global step 123586 with total reward 773.0\n",
            "Episode 693: time   133; reward 0.0; epsilon: 0.8775; loss: 0.000056; @ global step 123719 with total reward 773.0\n",
            "Episode 694: time   175; reward 1.0; epsilon: 0.8773; loss: 0.000032; @ global step 123894 with total reward 774.0\n",
            "Episode 695: time   291; reward 4.0; epsilon: 0.8771; loss: 0.000187; @ global step 124185 with total reward 778.0\n",
            "Episode 696: time   181; reward 1.0; epsilon: 0.8769; loss: 0.000048; @ global step 124366 with total reward 779.0\n",
            "Episode 697: time   136; reward 0.0; epsilon: 0.8767; loss: 0.000026; @ global step 124502 with total reward 779.0\n",
            "Episode 698: time   158; reward 1.0; epsilon: 0.8766; loss: 0.000025; @ global step 124660 with total reward 780.0\n",
            "Episode 699: time   148; reward 0.0; epsilon: 0.8764; loss: 0.000045; @ global step 124808 with total reward 780.0\n",
            "Episode 700: time   143; reward 0.0; epsilon: 0.8763; loss: 0.000276; @ global step 124951 with total reward 780.0\n",
            "Episode 701: time   174; reward 1.0; epsilon: 0.8761; loss: 0.000005; @ global step 125125 with total reward 781.0\n",
            "Episode 702: time   274; reward 4.0; epsilon: 0.8759; loss: 0.000100; @ global step 125399 with total reward 785.0\n",
            "Episode 703: time   201; reward 2.0; epsilon: 0.8757; loss: 0.000067; @ global step 125600 with total reward 787.0\n",
            "Episode 704: time   158; reward 0.0; epsilon: 0.8755; loss: 0.000057; @ global step 125758 with total reward 787.0\n",
            "Episode 705: time   134; reward 0.0; epsilon: 0.8754; loss: 0.000015; @ global step 125892 with total reward 787.0\n",
            "Episode 706: time   167; reward 1.0; epsilon: 0.8752; loss: 0.000004; @ global step 126059 with total reward 788.0\n",
            "Episode 707: time   230; reward 2.0; epsilon: 0.8750; loss: 0.000135; @ global step 126289 with total reward 790.0\n",
            "Episode 708: time   132; reward 0.0; epsilon: 0.8748; loss: 0.000153; @ global step 126421 with total reward 790.0\n",
            "Episode 709: time   129; reward 0.0; epsilon: 0.8747; loss: 0.000026; @ global step 126550 with total reward 790.0\n",
            "Episode 710: time   264; reward 3.0; epsilon: 0.8745; loss: 0.000171; @ global step 126814 with total reward 793.0\n",
            "Episode 711: time   218; reward 2.0; epsilon: 0.8742; loss: 0.000136; @ global step 127032 with total reward 795.0\n",
            "Episode 712: time   142; reward 0.0; epsilon: 0.8741; loss: 0.000095; @ global step 127174 with total reward 795.0\n",
            "Episode 713: time   128; reward 0.0; epsilon: 0.8740; loss: 0.000009; @ global step 127302 with total reward 795.0\n",
            "Episode 714: time   223; reward 2.0; epsilon: 0.8738; loss: 0.000016; @ global step 127525 with total reward 797.0\n",
            "Episode 715: time   247; reward 3.0; epsilon: 0.8735; loss: 0.000205; @ global step 127772 with total reward 800.0\n",
            "Episode 716: time   216; reward 2.0; epsilon: 0.8733; loss: 0.000017; @ global step 127988 with total reward 802.0\n",
            "Episode 717: time   243; reward 3.0; epsilon: 0.8731; loss: 0.000143; @ global step 128231 with total reward 805.0\n",
            "Episode 718: time   228; reward 3.0; epsilon: 0.8728; loss: 0.000061; @ global step 128459 with total reward 808.0\n",
            "Episode 719: time   241; reward 3.0; epsilon: 0.8726; loss: 0.000051; @ global step 128700 with total reward 811.0\n",
            "Episode 720: time   180; reward 1.0; epsilon: 0.8724; loss: 0.000007; @ global step 128880 with total reward 812.0\n",
            "Episode 721: time   160; reward 0.0; epsilon: 0.8723; loss: 0.000023; @ global step 129040 with total reward 812.0\n",
            "Episode 722: time   228; reward 3.0; epsilon: 0.8720; loss: 0.000054; @ global step 129268 with total reward 815.0\n",
            "Episode 723: time   258; reward 3.0; epsilon: 0.8718; loss: 0.000064; @ global step 129526 with total reward 818.0\n",
            "Episode 724: time   200; reward 2.0; epsilon: 0.8716; loss: 0.000033; @ global step 129726 with total reward 820.0\n",
            "Episode 725: time   142; reward 0.0; epsilon: 0.8714; loss: 0.000092; @ global step 129868 with total reward 820.0\n",
            "Episode 726: time   132; reward 1.0; epsilon: 0.8713; loss: 0.000024; @ global step 130000 with total reward 821.0\n",
            "Copied model parameters to target network.\n",
            "Episode 726: time   208; reward 2.0; epsilon: 0.8712; loss: 0.004652; @ global step 130076 with total reward 822.0\n",
            "Episode 727: time   211; reward 2.0; epsilon: 0.8710; loss: 0.000893; @ global step 130287 with total reward 824.0\n",
            "Episode 728: time   157; reward 0.0; epsilon: 0.8709; loss: 0.000129; @ global step 130444 with total reward 824.0\n",
            "Episode 729: time   138; reward 0.0; epsilon: 0.8707; loss: 0.000109; @ global step 130582 with total reward 824.0\n",
            "Episode 730: time   178; reward 1.0; epsilon: 0.8705; loss: 0.000047; @ global step 130760 with total reward 825.0\n",
            "Episode 731: time    35; reward 0.0; epsilon: 0.8705; loss: 0.001161; @ global step 130795 with total reward 825.0"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-0e16f50c302e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_net_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_proc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mdeep_q_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-0e16f50c302e>\u001b[0m in \u001b[0;36mdeep_q_learning\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCOMPRESS_ER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomp_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_batch\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-0e16f50c302e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCOMPRESS_ER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mmini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomp_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_batch\u001b[0m \u001b[0;34m=\u001b[0m             \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPSElEQVR4nO3df6zddX3H8efLVqYTxB+tiWmrsFim\nnZqBN4zFZbLglsKyNplG6UachtjoxC3TmeE0iviXmuli1k2rI6ibIJqM3MS6miiGzVnXS8DOlmDu\nKkrRhIsiy8IEce/9cb54z663nC/3fu+95X6ej+Sm5/s9n3POp5/cPu+358f3pqqQJK1/T1jrCUiS\nVofBl6RGGHxJaoTBl6RGGHxJaoTBl6RGTAx+kmuS3JPkmye5Pkk+nGQ2yZEk5w0/TUnScvU5wr8W\n2Pko118MbO++9gJ/t/xpSZKGNjH4VXUz8MNHGbIb+GSNHAKeluTZQ01QkjSMjQPcxxbgrrHtE92+\n7y8cmGQvo/8F8JSnPOUlz3/+8wd4eElqxy233HJvVW1eym2HCH5vVbUf2A8wNTVVMzMzq/nwkvS4\nl+Q7S73tEO/SuRvYNra9tdsnSTqFDBH8aeA13bt1LgDur6qfezpHkrS2Jj6lk+Q64EJgU5ITwLuB\nJwJU1UeAA8AlwCzwAPC6lZqsJGnpJga/qvZMuL6ANw02I0nSivCTtpLUCIMvSY0w+JLUCIMvSY0w\n+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLU\nCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUCIMv\nSY0w+JLUCIMvSY0w+JLUCIMvSY0w+JLUiF7BT7IzyR1JZpNcucj1z0lyU5JbkxxJcsnwU5UkLcfE\n4CfZAOwDLgZ2AHuS7Fgw7J3ADVV1LnAp8LdDT1SStDx9jvDPB2ar6nhVPQRcD+xeMKaAp3aXzwS+\nN9wUJUlD6BP8LcBdY9snun3jrgIuS3ICOAC8ebE7SrI3yUySmbm5uSVMV5K0VEO9aLsHuLaqtgKX\nAJ9K8nP3XVX7q2qqqqY2b9480ENLkvroE/y7gW1j21u7feMuB24AqKqvAU8CNg0xQUnSMPoE/zCw\nPcnZSU5j9KLs9IIx3wUuAkjyAkbB9zkbSTqFTAx+VT0MXAEcBG5n9G6co0muTrKrG/ZW4PVJvgFc\nB7y2qmqlJi1Jeuw29hlUVQcYvRg7vu9dY5ePAS8ddmqSpCH5SVtJaoTBl6RGGHxJaoTBl6RGGHxJ\naoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTB\nl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RG\nGHxJaoTBl6RGGHxJaoTBl6RG9Ap+kp1J7kgym+TKk4x5VZJjSY4m+fSw05QkLdfGSQOSbAD2Ab8N\nnAAOJ5muqmNjY7YDbwdeWlX3JXnWSk1YkrQ0fY7wzwdmq+p4VT0EXA/sXjDm9cC+qroPoKruGXaa\nkqTl6hP8LcBdY9snun3jzgHOSfLVJIeS7FzsjpLsTTKTZGZubm5pM5YkLclQL9puBLYDFwJ7gI8l\nedrCQVW1v6qmqmpq8+bNAz20JKmPPsG/G9g2tr212zfuBDBdVT+pqm8D32L0A0CSdIroE/zDwPYk\nZyc5DbgUmF4w5kZGR/ck2cToKZ7jA85TkrRME4NfVQ8DVwAHgduBG6rqaJKrk+zqhh0EfpDkGHAT\n8Laq+sFKTVqS9NilqtbkgaempmpmZmZNHluSHq+S3FJVU0u5rZ+0laRGGHxJaoTBl6RGGHxJaoTB\nl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RG\nGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJ\naoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RG9Ap+kp1J7kgym+TKRxn3iiSVZGq4KUqShjAx+Ek2APuA\ni4EdwJ4kOxYZdwbwp8DXh56kJGn5+hzhnw/MVtXxqnoIuB7Yvci49wLvA3484PwkSQPpE/wtwF1j\n2ye6fT+T5DxgW1V9/tHuKMneJDNJZubm5h7zZCVJS7fsF22TPAH4IPDWSWOran9VTVXV1ObNm5f7\n0JKkx6BP8O8Gto1tb+32PeIM4IXAV5LcCVwATPvCrSSdWvoE/zCwPcnZSU4DLgWmH7myqu6vqk1V\ndVZVnQUcAnZV1cyKzFiStCQTg19VDwNXAAeB24EbqupokquT7FrpCUqShrGxz6CqOgAcWLDvXScZ\ne+HypyVJGpqftJWkRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZek\nRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8\nSWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWpEr+An2ZnkjiSz\nSa5c5Pq3JDmW5EiSLyV57vBTlSQtx8TgJ9kA7AMuBnYAe5LsWDDsVmCqql4MfA54/9ATlSQtT58j\n/POB2ao6XlUPAdcDu8cHVNVNVfVAt3kI2DrsNCVJy9Un+FuAu8a2T3T7TuZy4AuLXZFkb5KZJDNz\nc3P9ZylJWrZBX7RNchkwBXxgseuran9VTVXV1ObNm4d8aEnSBBt7jLkb2Da2vbXb9/8keTnwDuBl\nVfXgMNOTJA2lzxH+YWB7krOTnAZcCkyPD0hyLvBRYFdV3TP8NCVJyzUx+FX1MHAFcBC4Hbihqo4m\nuTrJrm7YB4DTgc8muS3J9EnuTpK0Rvo8pUNVHQAOLNj3rrHLLx94XpKkgflJW0lqhMGXpEYYfElq\nhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGX\npEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYY\nfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqRK/gJ9mZ5I4ks0muXOT6X0jyme76ryc5a+iJ\nSpKWZ2Lwk2wA9gEXAzuAPUl2LBh2OXBfVT0P+BDwvqEnKklanj5H+OcDs1V1vKoeAq4Hdi8Ysxv4\nRHf5c8BFSTLcNCVJy7Wxx5gtwF1j2yeAXzvZmKp6OMn9wDOBe8cHJdkL7O02H0zyzaVMeh3axIK1\naphrMc+1mOdazPvlpd6wT/AHU1X7gf0ASWaqamo1H/9U5VrMcy3muRbzXIt5SWaWets+T+ncDWwb\n297a7Vt0TJKNwJnAD5Y6KUnS8PoE/zCwPcnZSU4DLgWmF4yZBv6ou/xK4MtVVcNNU5K0XBOf0ume\nk78COAhsAK6pqqNJrgZmqmoa+HvgU0lmgR8y+qEwyf5lzHu9cS3muRbzXIt5rsW8Ja9FPBCXpDb4\nSVtJaoTBl6RGrHjwPS3DvB5r8ZYkx5IcSfKlJM9di3muhklrMTbuFUkqybp9S16ftUjyqu5742iS\nT6/2HFdLj38jz0lyU5Jbu38nl6zFPFdakmuS3HOyzypl5MPdOh1Jcl6vO66qFfti9CLvfwK/BJwG\nfAPYsWDMHwMf6S5fCnxmJee0Vl891+K3gF/sLr+x5bXoxp0B3AwcAqbWet5r+H2xHbgVeHq3/ay1\nnvcarsV+4I3d5R3AnWs97xVai98EzgO+eZLrLwG+AAS4APh6n/td6SN8T8swb+JaVNVNVfVAt3mI\n0Wce1qM+3xcA72V0XqYfr+bkVlmftXg9sK+q7gOoqntWeY6rpc9aFPDU7vKZwPdWcX6rpqpuZvSO\nx5PZDXyyRg4BT0vy7En3u9LBX+y0DFtONqaqHgYeOS3DetNnLcZdzugn+Ho0cS26/6Juq6rPr+bE\n1kCf74tzgHOSfDXJoSQ7V212q6vPWlwFXJbkBHAAePPqTO2U81h7AqzyqRXUT5LLgCngZWs9l7WQ\n5AnAB4HXrvFUThUbGT2tcyGj//XdnORFVfWjNZ3V2tgDXFtVf5Xk1xl9/ueFVfW/az2xx4OVPsL3\ntAzz+qwFSV4OvAPYVVUPrtLcVtuktTgDeCHwlSR3MnqOcnqdvnDb5/viBDBdVT+pqm8D32L0A2C9\n6bMWlwM3AFTV14AnMTqxWmt69WShlQ6+p2WYN3EtkpwLfJRR7Nfr87QwYS2q6v6q2lRVZ1XVWYxe\nz9hVVUs+adQprM+/kRsZHd2TZBOjp3iOr+YkV0mftfgucBFAkhcwCv7cqs7y1DANvKZ7t84FwP1V\n9f1JN1rRp3Rq5U7L8LjTcy0+AJwOfLZ73fq7VbVrzSa9QnquRRN6rsVB4HeSHAN+Crytqtbd/4J7\nrsVbgY8l+TNGL+C+dj0eICa5jtEP+U3d6xXvBp4IUFUfYfT6xSXALPAA8Lpe97sO10qStAg/aStJ\njTD4ktQIgy9JjTD4ktQIgy9JjTD4WjeS/DTJbWNfJz0LZzf+DUleM8Dj3tm9P146pfm2TK0bSf67\nqk5fg8e9k9HZPO9d7ceWHguP8LXudUfg70/yH0n+Pcnzuv1XJfnz7vKfjP0uguu7fc9IcmO371CS\nF3f7n5nki9256T/O6BS1jzzWZd1j3Jbko0k2rMFfWVqUwdd68uQFT+m8euy6+6vqRcDfAH+9yG2v\nBM6tqhcDb+j2vQe4tdv3l8Anu/3vBv61qn4F+CfgOfCzj/q/GnhpVf0qo0/F/uGwf0Vp6TxbptaT\n/+lCu5jrxv780CLXHwH+McmNjM5dA/AbwCsAqurL3ZH9Uxn9corf7/Z/Psl93fiLgJcAh7tTYzwZ\nWM/nRNLjjMFXK+oklx/xu4xC/nvAO5K8aAmPEeATVfX2JdxWWnE+paNWvHrsz6+NX9Gdf39bVd0E\n/AWjU3SfDvwL3VMySS4E7q2q/2L0axf/oNt/MfD07q6+BLwyybO6656Rdfx7ifX44xG+1pMnJ7lt\nbPufq+qRt2Y+PckR4EFGv0Rj3AbgH5Kcyego/cNV9aMkVwHXdLd7gPnTeL8HuC7JUeDfGJ2yl6o6\nluSdwBe7HyI/Ad4EfGfov6i0FL4tU+ueb5uURnxKR5Ia4RG+JDXCI3xJaoTBl6RGGHxJaoTBl6RG\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGHxJasT/ATJO6oTmrn8NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOXIOs1jFOtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}